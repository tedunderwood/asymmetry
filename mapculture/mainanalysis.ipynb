{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main analysis for the \"mapping culture\" article.\n",
    "\n",
    "Ted Underwood and Richard Jean So\n",
    "\n",
    "This is an offshoot of a larger project, which is evolving slowly. We spun this off to make a subsidiary point. It branched from the main project back at [```../analysis/third_model_analysis1.ipynb.```](https://github.com/tedunderwood/asymmetry/blob/master/analysis/third_model_analysis1.ipynb)\n",
    "\n",
    "We've edited this notebook so that it not only tests the hypotheses tested in the ```third_model``` notebook, but does so using two different metrics: KL divergence and cosine distance. \n",
    "\n",
    "For weird historical reasons, different passes at this project got described as \"first supplement,\" \"second supplement,\" and so on. (We kept adding a few more volumes to the model to test hypotheses more thoroughly.) The results we're using here are described as \"fourth supplement,\" but the underlying metadata and topic model are the same as those used in the \"third supplement.\" The fourth supplement is just a calculation run on the third supplement that keeps better track of cosine distance.\n",
    "\n",
    "For the code used to measure the temporal asymmetries, see ```calculate_supp4_kld.py``` in this folder, and the worker script it calls, ```kld_calc_worker_supp4.py```\n",
    "\n",
    "The analysis in this notebook begins after those Python scripts have run on the campus cluster (it's a compute-intensive process and we split it both across multiple nodes and across multiple cores in each node). \n",
    "\n",
    "The Python scripts produce a series of \"summary files\" that describe novelty, transience, and (what Barron et al call) \"resonance\" for each volume. In the article text, we are probably going to rename resonance something like \"anticipation.\" We calculate this on cosine distance quite simply by subtracting the cosine distances measured from a given text *forward* (\"transience\") from the cosine distances measured *backward* (\"novelty\").\n",
    "\n",
    "#### complexities of the data\n",
    "\n",
    "We measured novelty and transience across temporal windows of different sizes (10, 25, and 40 years). We also experimented with a measurement that uses only the 5% or 20% of volumes closest to a given work when doing the calculation. These options make a slight difference, but in reporting results we emphasize an approach that uses a 25-year window, and all volumes in that window. That's the approach we originally preregistered. (Actually, we planned to use 10-, 20-, and 50-year windows, but slightly adjusted the plan when we realized a 50-year window would just produce a lot of NaNs).\n",
    "\n",
    "#### imports\n",
    "\n",
    "First, we import a few modules that will prove useful later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob, math, random\n",
    "from scipy.stats import pearsonr, zscore, ttest_ind\n",
    "from statistics import mean, stdev\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get metadata\n",
    "\n",
    "In order to analyze the data we will need a metadata table that includes information about volumes, including inferred biographical information about the author (age, gender, nationality) and columns that assign volumes to particular \"hypothesis\" and \"contrast\" sets.\n",
    "\n",
    "To trace how nationality prediction was done, see [```detect_americans```](https://github.com/tedunderwood/asymmetry/blob/master/analysis/detect_americans.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39784, 39)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['allcopiesofwork', 'author', 'copiesin25yrs', 'earlyedition', 'imprint',\n",
       "       'inferreddate', 'lastname', 'latestcomp', 'nationality', 'isusa',\n",
       "       'actualgender', 'likelygender', 'title', 'authordate', 'birth', 'age',\n",
       "       'recordid', 'best1821_1900', 'best1900_1950', 'best1950_1990',\n",
       "       'anybest', 'best1821_1900contrast', 'best1900_1950contrast',\n",
       "       'best1950_1990contrast', 'reviewed1850_1950',\n",
       "       'reviewed1850_1950contrast', 'heath', 'heathcontrast', 'mostdiscussed',\n",
       "       'mostdiscussedcontrast', 'usnorton', 'usnortoncontrast', 'nonusnorton',\n",
       "       'nonusnortoncontrast', 'preregistered', 'preregisteredcontrast',\n",
       "       'reviewed1965_1990', 'reviewed1965_1990contrast', 'toremove'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.read_csv('../supplement3/thirdmastermeta.tsv', sep = '\\t', index_col = 'docid')\n",
    "print(meta.shape)\n",
    "meta.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get data\n",
    "\n",
    "Now the data itself. This is broken into a number of \"summary files\" because the processing that produced it had to be distributed across a cluster. (The entropy calculation is done by comparing individual volumes to each other, and when you've got 40k vols, the number of cross-comparisons becomes fairly large.)\n",
    "\n",
    "So we first make a list of all the files we need. We'll do this twice, because the KLD data and cosine-similarity data are in separate files. First the KLD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../supp4results/supp4_0summary.tsv',\n",
       " '../supp4results/supp4_8000summary.tsv',\n",
       " '../supp4results/supp4_10000summary.tsv',\n",
       " '../supp4results/supp4_14000summary.tsv',\n",
       " '../supp4results/supp4_30000summary.tsv',\n",
       " '../supp4results/supp4_34000summary.tsv',\n",
       " '../supp4results/supp4_6000summary.tsv',\n",
       " '../supp4results/supp4_2000summary.tsv',\n",
       " '../supp4results/supp4_24000summary.tsv',\n",
       " '../supp4results/supp4_20000summary.tsv',\n",
       " '../supp4results/supp4_4000summary.tsv',\n",
       " '../supp4results/supp4_36000summary.tsv',\n",
       " '../supp4results/supp4_18000summary.tsv',\n",
       " '../supp4results/supp4_32000summary.tsv',\n",
       " '../supp4results/supp4_22000summary.tsv',\n",
       " '../supp4results/supp4_26000summary.tsv',\n",
       " '../supp4results/supp4_28000summary.tsv',\n",
       " '../supp4results/supp4_38000summary.tsv',\n",
       " '../supp4results/supp4_16000summary.tsv',\n",
       " '../supp4results/supp4_12000summary.tsv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = glob.glob('../supp4results/*0summary.tsv')\n",
    "paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and then loop across the list, reading them in ... and finally concatenate the data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39784, 36)\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for p in paths:\n",
    "    df = pd.read_csv(p, sep = '\\t', index_col = 'docid')\n",
    "    dfs.append(df)\n",
    "    \n",
    "klddata = pd.concat(dfs, verify_integrity = True)\n",
    "print(klddata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine data\n",
    "\n",
    "Now we do the same thing for the cosine summary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../supp4results/supp4_24000cossummary.tsv',\n",
       " '../supp4results/supp4_30000cossummary.tsv',\n",
       " '../supp4results/supp4_8000cossummary.tsv',\n",
       " '../supp4results/supp4_34000cossummary.tsv',\n",
       " '../supp4results/supp4_0cossummary.tsv',\n",
       " '../supp4results/supp4_20000cossummary.tsv',\n",
       " '../supp4results/supp4_2000cossummary.tsv',\n",
       " '../supp4results/supp4_10000cossummary.tsv',\n",
       " '../supp4results/supp4_14000cossummary.tsv',\n",
       " '../supp4results/supp4_6000cossummary.tsv',\n",
       " '../supp4results/supp4_32000cossummary.tsv',\n",
       " '../supp4results/supp4_26000cossummary.tsv',\n",
       " '../supp4results/supp4_18000cossummary.tsv',\n",
       " '../supp4results/supp4_22000cossummary.tsv',\n",
       " '../supp4results/supp4_36000cossummary.tsv',\n",
       " '../supp4results/supp4_12000cossummary.tsv',\n",
       " '../supp4results/supp4_38000cossummary.tsv',\n",
       " '../supp4results/supp4_4000cossummary.tsv',\n",
       " '../supp4results/supp4_16000cossummary.tsv',\n",
       " '../supp4results/supp4_28000cossummary.tsv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = glob.glob('../supp4results/*cossummary.tsv')\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39784, 36)\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for p in paths:\n",
    "    df = pd.read_csv(p, sep = '\\t', index_col = 'docid')\n",
    "    dfs.append(df)\n",
    "    \n",
    "cosdata = pd.concat(dfs, verify_integrity = True)\n",
    "print(cosdata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map a couple of columns from the metadata into our data\n",
    "\n",
    "In order to normalize the data to correct for edge effects, we need the **latest-possible-date-of-composition** from metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "klddata = klddata.join(meta.latestcomp, how = 'inner')\n",
    "cosdata = cosdata.join(meta.latestcomp, how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to normalize for nationality, because\n",
    "\n",
    "    1. A lot of our hypotheses are US-specific, and\n",
    "    2. resonance/anticipation tends to be slightly higher for US authors than for others, simply because the US fraction of the library **increases** across time.\n",
    "\n",
    "Given those two facts, it gives us slightly more confidence to calculate resonance/anticipation separately for US and for non-US authors. We could in principle also separate authors who are British, Canadian, Indian, and so forth, but since we have few hypotheses specific to those nationalities, the gains are likely to be outweighed by increases in fragility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a lot of these nationalities are inferred / estimated. Overall accuracy (combining manual ground truth and estimation) comes to about 88-89%; consult [```detect_americans```](https://github.com/tedunderwood/asymmetry/blob/master/analysis/detect_americans.ipynb) for details.\n",
    "\n",
    "We are also fully aware that people like Henry James move across the Atlantic halfway through their lives, that some volumes are collections combining authors of different nationalities, and so on. If we were to fully describe those nuances for each volume, a single \"nationality\" code would be grossly inadequate. It would also take a year or two of manual work, and as you'll see by the end of this notebook, wouldn't make much difference to our analysis.\n",
    "\n",
    "Nationality is not a central subject of inquiry in this project. We're generating a simplified, imperfect *model* of nationality merely because it helps us (imperfectly) factor out a confounding variable that has a modest effect on our results. We think that provides a slight interpretive advantage, but the conclusions of our study would not be profoundly altered if we ignored nationality; to estimate the size of the effect, you can consult [earlier notebooks and models where nationality is not factored out,](https://github.com/tedunderwood/asymmetry/blob/master/analysis/first_eda.ipynb) or look at the end of this notebook where we test hypotheses using both normalized and non-normalized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39784, 38)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klddata = klddata.join(meta.isusa, how = 'inner')\n",
    "cosdata = cosdata.join(meta.isusa, how = 'inner')\n",
    "klddata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially both ```klddata``` and ```cosdata``` have the same shape and the same columns. The only difference is that the values in one dataframe were produced by taking the KL divergence, and in the other, cosine similarity.\n",
    "\n",
    "#### a look at the structure of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['novelty_1.0_10', 'novelty_1.0_25', 'novelty_1.0_40', 'novelty_0.2_10',\n",
       "       'novelty_0.2_25', 'novelty_0.2_40', 'novelty_0.05_10',\n",
       "       'novelty_0.05_25', 'novelty_0.05_40', 'novelty_0.025_10',\n",
       "       'novelty_0.025_25', 'novelty_0.025_40', 'transience_1.0_10',\n",
       "       'transience_1.0_25', 'transience_1.0_40', 'transience_0.2_10',\n",
       "       'transience_0.2_25', 'transience_0.2_40', 'transience_0.05_10',\n",
       "       'transience_0.05_25', 'transience_0.05_40', 'transience_0.025_10',\n",
       "       'transience_0.025_25', 'transience_0.025_40', 'resonance_1.0_10',\n",
       "       'resonance_1.0_25', 'resonance_1.0_40', 'resonance_0.2_10',\n",
       "       'resonance_0.2_25', 'resonance_0.2_40', 'resonance_0.05_10',\n",
       "       'resonance_0.05_25', 'resonance_0.05_40', 'resonance_0.025_10',\n",
       "       'resonance_0.025_25', 'resonance_0.025_40', 'latestcomp', 'isusa'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klddata.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data to reflect the edge effects caused by topic modeling\n",
    "\n",
    "\"Normalize\" here means that we take a 7-year window of volumes that are by US authors (or non-US authors), and calculate z scores for volumes within that window. (I.e., subtract the mean and divide by standard deviation.) We replace the raw resonance/anticipation score for each volume with the z score calculated when it's at the center of the window.\n",
    "\n",
    "I have already explained why we normalize for nationality. The reason for normalizing by date is that distance calculations on topic vectors cannot be trusted to remain uniform across a timeline. There are edge-sampling effects which make distances lower toward the ends of the timeline. This is true for both cosine distance and KLD.\n",
    "Here's the loop where we actually do the normalizing. This does take some time to run (~20 min). There might be a simpler/quicker way to do this with an apply method, but it's a bit tricky, since we use a 7-year span to generate the z scores, but only copy over the scores for the central year.\n",
    "\n",
    "The result are two new dataframes called ```zcosdata``` and ```zklddata.``` This is the data that will be used in most subsequent analyses.\n",
    "\n",
    "In doing this, we also loop across columns and calculate a separate z score for each column. The reason is that resonance/anticipation can be calculated in a range of different ways--using different fractions of the dataset, and different temporal windows. There's a separate column for each of these possibilities. (Note, however, that we preregistered some guidelines about the modes of calculation we would actually use in checking hypotheses, to avoid a garden of infinitely forking paths.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1801\n",
      "1851\n",
      "1901\n",
      "1951\n",
      "2001\n",
      "1801\n",
      "1851\n",
      "1901\n",
      "1951\n",
      "2001\n"
     ]
    }
   ],
   "source": [
    "# normalize cosine-distance data\n",
    "\n",
    "zcosdata = cosdata.copy(deep = True)\n",
    "columns = [x for x in zcosdata.columns.tolist() if x.startswith('resonance')]\n",
    "\n",
    "for col in columns:\n",
    "    zcosdata[col] = np.nan\n",
    "    # set default as empty\n",
    "\n",
    "for yankeeness in [True, False]:\n",
    "    for yr in range(1800, 2009):\n",
    "        if yr % 50 == 1:\n",
    "            print(yr)\n",
    "        df = cosdata.loc[(cosdata.latestcomp >= yr - 3) & (cosdata.latestcomp <= yr + 3) & (cosdata.isusa == yankeeness), : ]\n",
    "        for col in columns:\n",
    "            nas = np.isnan(df[col])\n",
    "            seriestonormalize = df.loc[~nas, col]\n",
    "            nonnancount = np.count_nonzero(~np.isnan(seriestonormalize))\n",
    "            indices = seriestonormalize.index.values\n",
    "            \n",
    "            if nonnancount > 0:\n",
    "                zscores = zscore(seriestonormalize, nan_policy = 'omit')\n",
    "            else:\n",
    "                zscores = [np.nan] * len(indices)\n",
    "                \n",
    "            for idx, z in zip(indices, zscores):\n",
    "                date = df.loc[idx, 'latestcomp']\n",
    "                if date == yr:\n",
    "                    zcosdata.loc[idx, col] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1801\n",
      "1851\n",
      "1901\n",
      "1951\n",
      "2001\n",
      "1801\n",
      "1851\n",
      "1901\n",
      "1951\n",
      "2001\n"
     ]
    }
   ],
   "source": [
    "# normalize kld data\n",
    "\n",
    "zklddata = cosdata.copy(deep = True)\n",
    "columns = [x for x in zklddata.columns.tolist() if x.startswith('resonance')]\n",
    "\n",
    "for col in columns:\n",
    "    zklddata[col] = np.nan\n",
    "    # set default as empty\n",
    "\n",
    "for yankeeness in [True, False]:\n",
    "    for yr in range(1800, 2009):\n",
    "        if yr % 50 == 1:\n",
    "            print(yr)\n",
    "        df = klddata.loc[(cosdata.latestcomp >= yr - 3) & (klddata.latestcomp <= yr + 3) & (klddata.isusa == yankeeness), : ]\n",
    "        for col in columns:\n",
    "            nas = np.isnan(df[col])\n",
    "            seriestonormalize = df.loc[~nas, col]\n",
    "            nonnancount = np.count_nonzero(~np.isnan(seriestonormalize))\n",
    "            indices = seriestonormalize.index.values\n",
    "            \n",
    "            if nonnancount > 0:\n",
    "                zscores = zscore(seriestonormalize, nan_policy = 'omit')\n",
    "            else:\n",
    "                zscores = [np.nan] * len(indices)\n",
    "                \n",
    "            for idx, z in zip(indices, zscores):\n",
    "                date = df.loc[idx, 'latestcomp']\n",
    "                if date == yr:\n",
    "                    zklddata.loc[idx, col] = z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test first hypothesis: frequently purchased volumes have more resonance/anticipation\n",
    "\n",
    "The first hypothesis we test involves a correlation between two numeric variables: the anticipation (or resonance) score calculated for a volume and the number of copies of that volume attested in HathiTrust. The underlying theory here is that having a lot of copies in a library is a sign that a book was \"ahead of its time,\" either in the causal sense that it sold a lot of copies and therefore had an *influence* on the future, or in the reverse-causal sense that it became (retrospectively) attractive to librarians because literary history happened to move in its direction. Our experiment doesn't currently allow us to distinguish those causal mechanisms.\n",
    "\n",
    "To test this hypothesis we need a column from metadata that records the number of copies attested in Hathi libraries.\n",
    "\n",
    "(To see where this is calculated, you'll need to consult the [```noveltmmeta```](https://github.com/tedunderwood/noveltmmeta) repo.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "zklddata = zklddata.join(meta.allcopiesofwork, how = 'inner')\n",
    "zcosdata = zcosdata.join(meta.allcopiesofwork, how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First test reprinting hypothesis for KLD data\n",
    "\n",
    "Now we loop across the \"resonance\" columns to calculate correlation with number of attested volumes.\n",
    "\n",
    "Since reprinting is sort of a feast-or-famine thing--and high numbers of attested volumes might increase out of proportion to the resonance score--we also try correlation with log(num_vols), which indeed is slightly stronger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resonance_1.0_10 0.08728919746648668 7.215488840012418e-63\n",
      "log-transformed:  resonance_1.0_10 0.09530068959251048 1.2317250485910705e-74\n",
      "\n",
      "resonance_1.0_25 0.08441329007260154 5.096101444975824e-52\n",
      "log-transformed:  resonance_1.0_25 0.10088682829669138 1.2460851158212266e-73\n",
      "\n",
      "resonance_1.0_40 0.07993584501409841 1.1528321568896112e-38\n",
      "log-transformed:  resonance_1.0_40 0.0995640840050285 4.136257582308606e-59\n",
      "\n",
      "resonance_0.2_10 0.10524455571512012 1.0688293288462121e-90\n",
      "log-transformed:  resonance_0.2_10 0.1081091840319104 1.263064868489692e-95\n",
      "\n",
      "resonance_0.2_25 0.0983437071210339 4.847838580061924e-70\n",
      "log-transformed:  resonance_0.2_25 0.1074098904794799 2.8951403191967555e-83\n",
      "\n",
      "resonance_0.2_40 0.0977114014609437 5.484801926139876e-57\n",
      "log-transformed:  resonance_0.2_40 0.11067176080486792 1.1029149754733553e-72\n",
      "\n",
      "resonance_0.05_10 0.11059881991222634 5.12197690748345e-100\n",
      "log-transformed:  resonance_0.05_10 0.10966060871215587 2.3796698708407397e-98\n",
      "\n",
      "resonance_0.05_25 0.11422297370338053 5.536282434390997e-94\n",
      "log-transformed:  resonance_0.05_25 0.11744791311623634 2.722499345157404e-99\n",
      "\n",
      "resonance_0.05_40 0.11457545103500182 8.420931532578607e-78\n",
      "log-transformed:  resonance_0.05_40 0.12069460658956668 3.461776879518572e-86\n",
      "\n",
      "resonance_0.025_10 0.10187156956994185 4.5528842401607967e-85\n",
      "log-transformed:  resonance_0.025_10 0.10180919735594694 5.762735002754412e-85\n",
      "\n",
      "resonance_0.025_25 0.1132869514558498 1.8014850542398233e-92\n",
      "log-transformed:  resonance_0.025_25 0.11801563567556708 3.0538223427329226e-100\n",
      "\n",
      "resonance_0.025_40 0.11519782706462474 1.238184132393491e-78\n",
      "log-transformed:  resonance_0.025_40 0.12423780774556209 3.0143718762161243e-91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = [x for x in zklddata.columns.tolist() if x.startswith('resonance')]\n",
    "\n",
    "for col in columns:\n",
    "    nas = np.isnan(zklddata[col]) | np.isnan(zklddata['allcopiesofwork'])\n",
    "    r, p = pearsonr(zklddata.loc[~nas, col], zklddata.loc[~nas, 'allcopiesofwork'])\n",
    "    print(col, r, p)\n",
    "    r, p = pearsonr(zklddata.loc[~nas, col], np.log(zklddata.loc[~nas, 'allcopiesofwork'] + 0.64))\n",
    "    print(\"log-transformed: \", col, r, p)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculated resonance for 100% of the corpus, as well as the 20%, 5% and 2.5% of volumes closest to the volume being evaluated.\n",
    "\n",
    "We also measured across 10-, 25-, and 40-year windows.\n",
    "\n",
    "**Notice, however, that the differences between different measurement strategies are on the whole rather modest!** There's a gap of a little more than .02 in the strength of correlation, and all of the tests sail way, way under *p* < .05. The differences between measurement strategies may be greater for individual vols, but when you're looking at broad correlations or differences of means between groups, the measurement strategy is rarely determinative.\n",
    "\n",
    "### Now test reprinting hypothesis for cosines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resonance_1.0_10 0.06709482733592166 8.196622815642496e-38\n",
      "log-transformed:  resonance_1.0_10 0.07470698893466719 1.7407655993823467e-46\n",
      "\n",
      "resonance_1.0_25 0.07488757682412964 2.749824267044361e-41\n",
      "log-transformed:  resonance_1.0_25 0.089599669113016 2.0970210199481114e-58\n",
      "\n",
      "resonance_1.0_40 0.0750168203933484 3.034865989188687e-34\n",
      "log-transformed:  resonance_1.0_40 0.09393725069466383 8.677462861708137e-53\n",
      "\n",
      "resonance_0.2_10 0.08077950660533276 4.502056618201435e-54\n",
      "log-transformed:  resonance_0.2_10 0.08920704244683847 1.3682594742099138e-65\n",
      "\n",
      "resonance_0.2_25 0.08376437355976456 3.014651699434066e-51\n",
      "log-transformed:  resonance_0.2_25 0.09885536284788415 9.348337907917226e-71\n",
      "\n",
      "resonance_0.2_40 0.08377395306823843 2.615737487177438e-42\n",
      "log-transformed:  resonance_0.2_40 0.100463025359223 3.734037311965372e-60\n",
      "\n",
      "resonance_0.05_10 0.08510528969854922 7.680229943793652e-60\n",
      "log-transformed:  resonance_0.05_10 0.09140352291298101 8.815119349382746e-69\n",
      "\n",
      "resonance_0.05_25 0.09114073212058982 2.2400121103801427e-60\n",
      "log-transformed:  resonance_0.05_25 0.10298752463293034 1.1480585966307467e-76\n",
      "\n",
      "resonance_0.05_40 0.08976099488815478 2.4575438519004357e-48\n",
      "log-transformed:  resonance_0.05_40 0.1034590889813056 1.0532245338560463e-63\n",
      "\n",
      "resonance_0.025_10 0.085554415605205 1.8584644216693244e-60\n",
      "log-transformed:  resonance_0.025_10 0.09046049541003082 2.1125870882931354e-67\n",
      "\n",
      "resonance_0.025_25 0.09557147727104329 3.1131974213938175e-66\n",
      "log-transformed:  resonance_0.025_25 0.1050289852345829 1.1196822935791435e-79\n",
      "\n",
      "resonance_0.025_40 0.09377699746779974 1.2971741047383545e-52\n",
      "log-transformed:  resonance_0.025_40 0.10556485175726014 2.91295978779827e-66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in columns:\n",
    "    nas = np.isnan(zcosdata[col]) | np.isnan(zcosdata['allcopiesofwork'])\n",
    "    r, p = pearsonr(zcosdata.loc[~nas, col], zcosdata.loc[~nas, 'allcopiesofwork'])\n",
    "    print(col, r, p)\n",
    "    r, p = pearsonr(zcosdata.loc[~nas, col], np.log(zcosdata.loc[~nas, 'allcopiesofwork'] + 0.64))\n",
    "    print(\"log-transformed: \", col, r, p)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlations are about .02 lower, across the board. Again notice that **it doesn't make a huge difference whether you use cosine distance or KL divergence to test this.** KLD is definitely preferable, for reasons that are probably stated correctly in Barron et al. But the general strategy of subtracting forward-difference from backward-difference is the key innovation in that article. \n",
    "\n",
    "### Testing the first hypothesis without normalization\n",
    "\n",
    "Notice also what makes a bigger difference than KLD/cos: normalizing the data to correct for edge effects in topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resonance_1.0_10 0.04834811122565821 2.0968809631470307e-20\n",
      "log-transformed:  resonance_1.0_10 0.023091191166847325 9.901629775302134e-06\n",
      "\n",
      "resonance_1.0_25 0.025822315683363316 3.5712850347872804e-06\n",
      "log-transformed:  resonance_1.0_25 0.013255779737391749 0.0173592420339194\n",
      "\n",
      "resonance_1.0_40 0.025123494220364594 4.476993764925497e-05\n",
      "log-transformed:  resonance_1.0_40 0.01760817637336868 0.004232893465470963\n",
      "\n",
      "resonance_0.2_10 0.11355514935724816 2.2993226836268e-105\n",
      "log-transformed:  resonance_0.2_10 0.08886380975132954 4.243474442567562e-65\n",
      "\n",
      "resonance_0.2_25 0.05256783341877011 3.712185157866457e-21\n",
      "log-transformed:  resonance_0.2_25 0.03304437832035578 2.9959505985579938e-09\n",
      "\n",
      "resonance_0.2_40 0.03398270140009869 3.365013676219131e-08\n",
      "log-transformed:  resonance_0.2_40 0.016127004620531918 0.00880252624247758\n",
      "\n",
      "resonance_0.05_10 0.13224645111238742 1.5814306356708203e-142\n",
      "log-transformed:  resonance_0.05_10 0.10910732690639938 2.253393648943615e-97\n",
      "\n",
      "resonance_0.05_25 0.08285475867099987 3.558768592143476e-50\n",
      "log-transformed:  resonance_0.05_25 0.059318769616998654 1.655478455313489e-26\n",
      "\n",
      "resonance_0.05_40 0.0534478643523775 3.702388560327166e-18\n",
      "log-transformed:  resonance_0.05_40 0.02648276392881803 1.690587142402709e-05\n",
      "\n",
      "resonance_0.025_10 0.12193994513713188 2.561288422831234e-121\n",
      "log-transformed:  resonance_0.025_10 0.1038492527603331 2.4000517696943513e-88\n",
      "\n",
      "resonance_0.025_25 0.07512224620380412 1.5501439925656954e-41\n",
      "log-transformed:  resonance_0.025_25 0.055496053093740574 2.123449229832946e-23\n",
      "\n",
      "resonance_0.025_40 0.04327922122786885 2.021318268069003e-12\n",
      "log-transformed:  resonance_0.025_40 0.019620888759610107 0.0014362409443431329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "klddata = klddata.join(meta.allcopiesofwork, how = 'inner')\n",
    "\n",
    "for col in columns:\n",
    "    nas = np.isnan(klddata[col]) | np.isnan(klddata['allcopiesofwork'])\n",
    "    r, p = pearsonr(klddata.loc[~nas, col], klddata.loc[~nas, 'allcopiesofwork'])\n",
    "    print(col, r, p)\n",
    "    r, p = pearsonr(klddata.loc[~nas, col], np.log(klddata.loc[~nas, 'allcopiesofwork'] + 0.64))\n",
    "    print(\"log-transformed: \", col, r, p)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a much weaker signal. It still confirms the hypothesis. But normalizing the data makes the correlation substantially stronger--usually more than doubling it. In particular it has a big effect on measurements that use a long temporal window and/or all the volumes. Those seem to be heavily distorted by nationality and/or edge effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other hypotheses\n",
    "\n",
    "Most of the hypotheses that remain can be understood as binary comparisons between the means of two samples, and tested using a t-test. To make this systematic and reduce code repetition, we'll define a function that can be used to test a hypothesis about a given category--which we pass as an argument to the function.\n",
    "\n",
    "In each case, we've developed a very cautious test, to avoid worries about confounding variables. For each hypothesis set of volumes we have randomly selected a contrast set (matched as closely as practical to the hypothesis set in genre, nationality, and date). The [matching strategy](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2943670/) is a way of addressing confounding variables without some of the slipperiness of a complex regression.\n",
    "\n",
    "Then we run a t test on resonance for each of these categories. \n",
    "\n",
    "The test we are relying on as actually confirming the hypothesis is a pre-registered one: we measure resonance at the 25-year window, using all the volumes. This is the column ```resonance_1.0_25.``` (Actually, we pre-registered a plan to test 10, 20, and 50-year windows, whereas here we have 10, 25 and 40 year windows, but the difference between 20- and 25-year windows is not determinative at all.) For the sake of guiding future research, we also run a version of this test using only the 5% of volumes closest to the work in a given year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testahypothesis(hypothesis_cat, data, meta):\n",
    "    contrast_cat = hypothesis_cat + 'contrast'\n",
    "    \n",
    "    hypodocs = meta.index[meta[hypothesis_cat] == 1].tolist()\n",
    "    contradocs = meta.index[meta[contrast_cat] == 1].tolist()\n",
    "    \n",
    "    testoverlap = set(hypodocs).intersection(set(contradocs))\n",
    "    print(len(testoverlap))\n",
    "    \n",
    "    columns = ['resonance_1.0_25', 'resonance_0.05_25']\n",
    "    \n",
    "    for col in columns:\n",
    "        hypothesis_data = data.loc[hypodocs, col]\n",
    "        hypothesis_data = hypothesis_data[~np.isnan(hypothesis_data)]\n",
    "        \n",
    "        contrast_data = data.loc[contradocs, col]\n",
    "        contrast_data = contrast_data[~np.isnan(contrast_data)]\n",
    "        \n",
    "        t, p = ttest_ind(hypothesis_data, contrast_data)\n",
    "        print(col, \"t-test\", t, p)\n",
    "        a = hypothesis_data\n",
    "        b = contrast_data\n",
    "        cohens_d = (mean(a) - mean(b)) / (sqrt((stdev(a) ** 2 + stdev(b) ** 2) / 2))\n",
    "        print(col, \"Cohen's d\", cohens_d)\n",
    "        print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing hypothesis using KLD measurements\n",
    "\n",
    "We have ten hypothesis categories to check: bestsellers in three chronological periods (these labels begin ```best```); volumes reviewed in elite venues 1850-1950, or the most-reviewed volumes 1965-1990; a list of the most-discussed author-title combinations in the JSTOR corpus; US authors anthologized in Heath; US authors anthologized in Norton or Norton Short Fiction; and non-US authors anthologized in the *Norton Anthology of English Literature.*\n",
    "\n",
    "Finally, we preregistered a list of 20 books that we expected to be influential or ahead of their time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best1821_1900\n",
      "1\n",
      "resonance_1.0_25 t-test 4.728228445527444 3.65220964201985e-06\n",
      "resonance_1.0_25 Cohen's d 0.5733819206752837\n",
      "\n",
      "resonance_0.05_25 t-test 5.459700631524944 1.081163170769938e-07\n",
      "resonance_0.05_25 Cohen's d 0.6620859525890821\n",
      "\n",
      "\n",
      "best1900_1950\n",
      "0\n",
      "resonance_1.0_25 t-test 2.684897540560066 0.007687903350588126\n",
      "resonance_1.0_25 Cohen's d 0.31976664371048014\n",
      "\n",
      "resonance_0.05_25 t-test 2.1143308753730046 0.035370867857592074\n",
      "resonance_0.05_25 Cohen's d 0.2518131427728281\n",
      "\n",
      "\n",
      "best1950_1990\n",
      "0\n",
      "resonance_1.0_25 t-test -1.227309009512024 0.22091398442888913\n",
      "resonance_1.0_25 Cohen's d -0.15807951902442088\n",
      "\n",
      "resonance_0.05_25 t-test -1.8249982605659993 0.06924950717539169\n",
      "resonance_0.05_25 Cohen's d -0.23497939371407023\n",
      "\n",
      "\n",
      "reviewed1850_1950\n",
      "0\n",
      "resonance_1.0_25 t-test 8.112970035262245 1.2661947495462621e-15\n",
      "resonance_1.0_25 Cohen's d 0.48171084616545207\n",
      "\n",
      "resonance_0.05_25 t-test 8.71727776809012 9.874472549286122e-18\n",
      "resonance_0.05_25 Cohen's d 0.5168601717583481\n",
      "\n",
      "\n",
      "heath\n",
      "0\n",
      "resonance_1.0_25 t-test 0.5729283879531895 0.5682236923317783\n",
      "resonance_1.0_25 Cohen's d 0.12348009272915601\n",
      "\n",
      "resonance_0.05_25 t-test -0.17145652445745094 0.8642771802819541\n",
      "resonance_0.05_25 Cohen's d -0.03690030081119217\n",
      "\n",
      "\n",
      "mostdiscussed\n",
      "0\n",
      "resonance_1.0_25 t-test 1.5758647629212292 0.12112197785718982\n",
      "resonance_1.0_25 Cohen's d 0.42889606364322164\n",
      "\n",
      "resonance_0.05_25 t-test 2.7118443629391327 0.00904793775282696\n",
      "resonance_0.05_25 Cohen's d 0.7380705501159762\n",
      "\n",
      "\n",
      "usnorton\n",
      "0\n",
      "resonance_1.0_25 t-test 0.33720091522357826 0.7366322176966928\n",
      "resonance_1.0_25 Cohen's d 0.06489434639177362\n",
      "\n",
      "resonance_0.05_25 t-test -0.1964483342884424 0.844635412396912\n",
      "resonance_0.05_25 Cohen's d -0.03780649956109531\n",
      "\n",
      "\n",
      "nonusnorton\n",
      "0\n",
      "resonance_1.0_25 t-test 2.2170792232921483 0.02905468571005567\n",
      "resonance_1.0_25 Cohen's d 0.45532228285737303\n",
      "\n",
      "resonance_0.05_25 t-test 2.726800678151675 0.007643952023549938\n",
      "resonance_0.05_25 Cohen's d 0.5611191403922763\n",
      "\n",
      "\n",
      "preregistered\n",
      "0\n",
      "resonance_1.0_25 t-test 3.5165866921182998 0.0012019650475790908\n",
      "resonance_1.0_25 Cohen's d 1.1409313814499153\n",
      "\n",
      "resonance_0.05_25 t-test 4.236648090627981 0.00015027037334592466\n",
      "resonance_0.05_25 Cohen's d 1.3745501481852054\n",
      "\n",
      "\n",
      "reviewed1965_1990\n",
      "0\n",
      "resonance_1.0_25 t-test 2.122079135586434 0.03554271812457462\n",
      "resonance_1.0_25 Cohen's d 0.3514383874497575\n",
      "\n",
      "resonance_0.05_25 t-test 0.8211501373582003 0.4129181311944121\n",
      "resonance_0.05_25 Cohen's d 0.13585136401686135\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols2check = ['best1821_1900',\n",
    "       'best1900_1950', 'best1950_1990', 'reviewed1850_1950', 'heath', \n",
    "        'mostdiscussed', 'usnorton', 'nonusnorton', 'preregistered',\n",
    "       'reviewed1965_1990']\n",
    "\n",
    "for col in cols2check:\n",
    "    print(col)\n",
    "    testahypothesis(col, zklddata, meta)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### analysis\n",
    "\n",
    "There are a number of clearly significant confirmations: well-reviewed books both 1850-1950 and 1965-1990. Our preregistered 20 vols, also the non-US Norton vols. Bestsellers until 1950. (After 1950, interestingly, the effect of being bestseller is negative.)\n",
    "\n",
    "Heath, usnorton, and mostdiscussed are not significant effects. For all of those groups, n is pretty small. On the other hand, nonusnorton and preregistered are significant with a sample size that is no larger, so the negative result here seems meaningful. Academic canonicity is a somewhat less reliable sign of precocity than being well-reviewed, or being a bestseller up to 1950.\n",
    "\n",
    "The declining significance of bestsellerdom as time passes is pretty clear.\n",
    "\n",
    "There's also one error in there: the \"1\" instead of a \"0\" in best1821_1900 suggests that we have a tiny overlap between the hypothesis and contrast set. That shouldn't happen. I will set about fixing.\n",
    "\n",
    "### Testing binary hypotheses using cosine distances\n",
    "\n",
    "Now let's see how much difference it makes if we use cosine distances instead of KL divergences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best1821_1900\n",
      "1\n",
      "resonance_1.0_25 t-test 4.894647697375073 1.6963582661828981e-06\n",
      "resonance_1.0_25 Cohen's d 0.5935632193077556\n",
      "\n",
      "resonance_0.05_25 t-test 4.30857911999433 2.3033102530687738e-05\n",
      "resonance_0.05_25 Cohen's d 0.5224919649431591\n",
      "\n",
      "\n",
      "best1900_1950\n",
      "0\n",
      "resonance_1.0_25 t-test 2.3410346652946297 0.019932106074257244\n",
      "resonance_1.0_25 Cohen's d 0.2788131712374385\n",
      "\n",
      "resonance_0.05_25 t-test 1.763207019067235 0.07895631739793006\n",
      "resonance_0.05_25 Cohen's d 0.20999490004236038\n",
      "\n",
      "\n",
      "best1950_1990\n",
      "0\n",
      "resonance_1.0_25 t-test -1.7003277242367345 0.09037012587394383\n",
      "resonance_1.0_25 Cohen's d -0.21897056652846222\n",
      "\n",
      "resonance_0.05_25 t-test -1.1594983984105531 0.24741016661201073\n",
      "resonance_0.05_25 Cohen's d -0.14928473228184286\n",
      "\n",
      "\n",
      "reviewed1850_1950\n",
      "0\n",
      "resonance_1.0_25 t-test 8.66876871479035 1.4740017877087207e-17\n",
      "resonance_1.0_25 Cohen's d 0.5143872498973918\n",
      "\n",
      "resonance_0.05_25 t-test 8.442433945553981 9.3178953094924e-17\n",
      "resonance_0.05_25 Cohen's d 0.5009677215425673\n",
      "\n",
      "\n",
      "heath\n",
      "0\n",
      "resonance_1.0_25 t-test 0.9661646544497429 0.336735258138082\n",
      "resonance_1.0_25 Cohen's d 0.20838759084637742\n",
      "\n",
      "resonance_0.05_25 t-test 0.6426903094012367 0.5221754724665545\n",
      "resonance_0.05_25 Cohen's d 0.1385321558264372\n",
      "\n",
      "\n",
      "mostdiscussed\n",
      "0\n",
      "resonance_1.0_25 t-test 1.80120239378128 0.07747064732971883\n",
      "resonance_1.0_25 Cohen's d 0.4902251986937503\n",
      "\n",
      "resonance_0.05_25 t-test 2.5808073134360754 0.012718260334351845\n",
      "resonance_0.05_25 Cohen's d 0.7024067824846083\n",
      "\n",
      "\n",
      "usnorton\n",
      "0\n",
      "resonance_1.0_25 t-test 0.21295632047366217 0.8317700514106994\n",
      "resonance_1.0_25 Cohen's d 0.040983462983700446\n",
      "\n",
      "resonance_0.05_25 t-test 0.1550228166515986 0.8770981366970854\n",
      "resonance_0.05_25 Cohen's d 0.029834154974778215\n",
      "\n",
      "\n",
      "nonusnorton\n",
      "0\n",
      "resonance_1.0_25 t-test 2.3628780297404033 0.02021664005566025\n",
      "resonance_1.0_25 Cohen's d 0.4848727829602496\n",
      "\n",
      "resonance_0.05_25 t-test 2.3609875729883276 0.02031396578275761\n",
      "resonance_0.05_25 Cohen's d 0.4843310091819741\n",
      "\n",
      "\n",
      "preregistered\n",
      "0\n",
      "resonance_1.0_25 t-test 3.201555270239253 0.0028552696919977717\n",
      "resonance_1.0_25 Cohen's d 1.0387216915337885\n",
      "\n",
      "resonance_0.05_25 t-test 3.912823511814946 0.0003885185198255599\n",
      "resonance_0.05_25 Cohen's d 1.2694875814409634\n",
      "\n",
      "\n",
      "reviewed1965_1990\n",
      "0\n",
      "resonance_1.0_25 t-test 2.392482899704717 0.01802471189544939\n",
      "resonance_1.0_25 Cohen's d 0.39571842140669616\n",
      "\n",
      "resonance_0.05_25 t-test 1.584839330563383 0.1151964955215957\n",
      "resonance_0.05_25 Cohen's d 0.2616334875650625\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols2check = ['best1821_1900',\n",
    "       'best1900_1950', 'best1950_1990', 'reviewed1850_1950', 'heath', \n",
    "        'mostdiscussed', 'usnorton', 'nonusnorton', 'preregistered',\n",
    "       'reviewed1965_1990']\n",
    "\n",
    "for col in cols2check:\n",
    "    print(col)\n",
    "    testahypothesis(col, zcosdata, meta)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as I can see there is no major difference; the hypotheses confirmed with KLD are also confirmed with cosine distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing hypotheses using non-normalized data\n",
    "\n",
    "does this make a difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best1821_1900\n",
      "1\n",
      "resonance_1.0_25 t-test 4.182075022171092 3.9082615701701506e-05\n",
      "resonance_1.0_25 Cohen's d 0.507151089725551\n",
      "\n",
      "resonance_0.05_25 t-test 4.879865872551955 1.817428398324364e-06\n",
      "resonance_0.05_25 Cohen's d 0.5917706597464294\n",
      "\n",
      "\n",
      "best1900_1950\n",
      "0\n",
      "resonance_1.0_25 t-test 2.513992800166754 0.0124984220008915\n",
      "resonance_1.0_25 Cohen's d 0.29941218533573694\n",
      "\n",
      "resonance_0.05_25 t-test 1.9780242952747935 0.04890614473343739\n",
      "resonance_0.05_25 Cohen's d 0.2355792653249139\n",
      "\n",
      "\n",
      "best1950_1990\n",
      "0\n",
      "resonance_1.0_25 t-test -1.0548372414774256 0.2925649318850847\n",
      "resonance_1.0_25 Cohen's d -0.1359274217851787\n",
      "\n",
      "resonance_0.05_25 t-test -1.7965925209078857 0.07366302129819756\n",
      "resonance_0.05_25 Cohen's d -0.2313211297690837\n",
      "\n",
      "\n",
      "reviewed1850_1950\n",
      "0\n",
      "resonance_1.0_25 t-test 6.078234982082009 1.6538365084700576e-09\n",
      "resonance_1.0_25 Cohen's d 0.3609528297449262\n",
      "\n",
      "resonance_0.05_25 t-test 7.289421643756135 5.798815325875458e-13\n",
      "resonance_0.05_25 Cohen's d 0.43162253237097886\n",
      "\n",
      "\n",
      "heath\n",
      "0\n",
      "resonance_1.0_25 t-test 0.697160189665687 0.48762757733645967\n",
      "resonance_1.0_25 Cohen's d 0.15019955591315395\n",
      "\n",
      "resonance_0.05_25 t-test -0.4815998364543825 0.6313425643948118\n",
      "resonance_0.05_25 Cohen's d -0.10358240201877814\n",
      "\n",
      "\n",
      "mostdiscussed\n",
      "0\n",
      "resonance_1.0_25 t-test 1.242959169873501 0.2194583588486102\n",
      "resonance_1.0_25 Cohen's d 0.3382906374781595\n",
      "\n",
      "resonance_0.05_25 t-test 2.21528308622931 0.031144407916093984\n",
      "resonance_0.05_25 Cohen's d 0.6029236885644174\n",
      "\n",
      "\n",
      "usnorton\n",
      "0\n",
      "resonance_1.0_25 t-test 0.2847127364169316 0.7764197248976894\n",
      "resonance_1.0_25 Cohen's d 0.054792991670676666\n",
      "\n",
      "resonance_0.05_25 t-test -0.27656793669578955 0.7826504395540321\n",
      "resonance_0.05_25 Cohen's d -0.05322552423351109\n",
      "\n",
      "\n",
      "nonusnorton\n",
      "0\n",
      "resonance_1.0_25 t-test 2.2730607490919534 0.025324727077765164\n",
      "resonance_1.0_25 Cohen's d 0.46703484851296323\n",
      "\n",
      "resonance_0.05_25 t-test 2.775902798864129 0.006655806196931587\n",
      "resonance_0.05_25 Cohen's d 0.571484087699025\n",
      "\n",
      "\n",
      "preregistered\n",
      "0\n",
      "resonance_1.0_25 t-test 2.700302424577903 0.0104901774852431\n",
      "resonance_1.0_25 Cohen's d 0.8760937935957426\n",
      "\n",
      "resonance_0.05_25 t-test 3.291213325360756 0.0022395288432388027\n",
      "resonance_0.05_25 Cohen's d 1.067810605769049\n",
      "\n",
      "\n",
      "reviewed1965_1990\n",
      "0\n",
      "resonance_1.0_25 t-test 2.4754180826977374 0.014467573582316517\n",
      "resonance_1.0_25 Cohen's d 0.40960004416286233\n",
      "\n",
      "resonance_0.05_25 t-test 1.1581353255146967 0.2487260073136839\n",
      "resonance_0.05_25 Cohen's d 0.1916615513993298\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols2check = ['best1821_1900',\n",
    "       'best1900_1950', 'best1950_1990', 'reviewed1850_1950', 'heath', \n",
    "        'mostdiscussed', 'usnorton', 'nonusnorton', 'preregistered',\n",
    "       'reviewed1965_1990']\n",
    "\n",
    "for col in cols2check:\n",
    "    print(col)\n",
    "    testahypothesis(col, klddata, meta)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't see cases where a hypothesis confirmed with normalized data is not confirmed with the raw data. But the effect sizes are generally weaker if we don't normalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific preregistered volumes\n",
    "\n",
    "When we consciously aimed at things we expected to be \"like the future,\" our aim was true. Statistically significant even at n = 20, and effect sizes are huge.\n",
    "\n",
    "Which volumes in particular create this effect? Note that these are z scores, so the mean for each column (in the whole collection is 0 and sd is 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resonance_1.0_25</th>\n",
       "      <th>resonance_0.05_40</th>\n",
       "      <th>resonance_1.0_10</th>\n",
       "      <th>latestcomp</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>docid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nyp.33433074943634</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.568580</td>\n",
       "      <td>1813</td>\n",
       "      <td>Austen, Jane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdp.39015062084390</th>\n",
       "      <td>2.141427</td>\n",
       "      <td>1.469642</td>\n",
       "      <td>1.698105</td>\n",
       "      <td>1955</td>\n",
       "      <td>Nabokov, Vladimir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uc2.ark+=13960=t3cz3334b</th>\n",
       "      <td>1.497907</td>\n",
       "      <td>1.576004</td>\n",
       "      <td>0.735204</td>\n",
       "      <td>1884</td>\n",
       "      <td>Twain, Mark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uva.x000380956</th>\n",
       "      <td>-0.370519</td>\n",
       "      <td>0.211187</td>\n",
       "      <td>-0.377158</td>\n",
       "      <td>1865</td>\n",
       "      <td>Verne, Jules</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nyp.33433076030760</th>\n",
       "      <td>0.283792</td>\n",
       "      <td>0.469276</td>\n",
       "      <td>0.192853</td>\n",
       "      <td>1844</td>\n",
       "      <td>Poe, Edgar Allan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inu.39000003707283</th>\n",
       "      <td>1.326140</td>\n",
       "      <td>1.500688</td>\n",
       "      <td>0.923641</td>\n",
       "      <td>1892</td>\n",
       "      <td>Doyle, Arthur Conan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uva.x000464259</th>\n",
       "      <td>0.077498</td>\n",
       "      <td>0.243171</td>\n",
       "      <td>0.276871</td>\n",
       "      <td>1850</td>\n",
       "      <td>Hawthorne, Nathaniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdp.39015000695182</th>\n",
       "      <td>1.899186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.325339</td>\n",
       "      <td>1972</td>\n",
       "      <td>Atwood, Margaret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uc2.ark+=13960=t1hh6d619</th>\n",
       "      <td>1.094664</td>\n",
       "      <td>1.529024</td>\n",
       "      <td>0.689373</td>\n",
       "      <td>1900</td>\n",
       "      <td>Dreiser, Theodore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uc1.32106002103940</th>\n",
       "      <td>1.406360</td>\n",
       "      <td>1.560343</td>\n",
       "      <td>0.794301</td>\n",
       "      <td>1952</td>\n",
       "      <td>Ellison, Ralph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdp.39015066409924</th>\n",
       "      <td>1.038430</td>\n",
       "      <td>1.419004</td>\n",
       "      <td>1.223019</td>\n",
       "      <td>1940</td>\n",
       "      <td>Wright, Richard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdp.39015066065254</th>\n",
       "      <td>0.899109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.632648</td>\n",
       "      <td>1973</td>\n",
       "      <td>Pynchon, Thomas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dul1.ark+=13960=t98637h6g</th>\n",
       "      <td>2.851193</td>\n",
       "      <td>2.418334</td>\n",
       "      <td>1.485716</td>\n",
       "      <td>1895</td>\n",
       "      <td>Wells, H. G. (Herbert George)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inu.30000007102522</th>\n",
       "      <td>1.497735</td>\n",
       "      <td>1.441246</td>\n",
       "      <td>0.868940</td>\n",
       "      <td>1925</td>\n",
       "      <td>Fitzgerald, F. Scott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nyp.33433074890454</th>\n",
       "      <td>-0.104394</td>\n",
       "      <td>0.180393</td>\n",
       "      <td>-0.043819</td>\n",
       "      <td>1851</td>\n",
       "      <td>Melville, Herman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uc1.b4713109</th>\n",
       "      <td>1.391817</td>\n",
       "      <td>0.961180</td>\n",
       "      <td>1.334026</td>\n",
       "      <td>1847</td>\n",
       "      <td>Bront, Charlotte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdp.39015021862308</th>\n",
       "      <td>0.527093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.437024</td>\n",
       "      <td>1977</td>\n",
       "      <td>Morrison, Toni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdp.39015031600409</th>\n",
       "      <td>2.313861</td>\n",
       "      <td>2.127114</td>\n",
       "      <td>1.179059</td>\n",
       "      <td>1945</td>\n",
       "      <td>Chandler, Raymond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nyp.33433081852711</th>\n",
       "      <td>-0.471735</td>\n",
       "      <td>-0.158815</td>\n",
       "      <td>-0.494849</td>\n",
       "      <td>1882</td>\n",
       "      <td>James, Henry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdp.39015004063601</th>\n",
       "      <td>1.171081</td>\n",
       "      <td>1.519079</td>\n",
       "      <td>1.828535</td>\n",
       "      <td>1939</td>\n",
       "      <td>Steinbeck, John</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           resonance_1.0_25  resonance_0.05_40  \\\n",
       "docid                                                            \n",
       "nyp.33433074943634                      NaN                NaN   \n",
       "mdp.39015062084390                 2.141427           1.469642   \n",
       "uc2.ark+=13960=t3cz3334b           1.497907           1.576004   \n",
       "uva.x000380956                    -0.370519           0.211187   \n",
       "nyp.33433076030760                 0.283792           0.469276   \n",
       "inu.39000003707283                 1.326140           1.500688   \n",
       "uva.x000464259                     0.077498           0.243171   \n",
       "mdp.39015000695182                 1.899186                NaN   \n",
       "uc2.ark+=13960=t1hh6d619           1.094664           1.529024   \n",
       "uc1.32106002103940                 1.406360           1.560343   \n",
       "mdp.39015066409924                 1.038430           1.419004   \n",
       "mdp.39015066065254                 0.899109                NaN   \n",
       "dul1.ark+=13960=t98637h6g          2.851193           2.418334   \n",
       "inu.30000007102522                 1.497735           1.441246   \n",
       "nyp.33433074890454                -0.104394           0.180393   \n",
       "uc1.b4713109                       1.391817           0.961180   \n",
       "mdp.39015021862308                 0.527093                NaN   \n",
       "mdp.39015031600409                 2.313861           2.127114   \n",
       "nyp.33433081852711                -0.471735          -0.158815   \n",
       "mdp.39015004063601                 1.171081           1.519079   \n",
       "\n",
       "                           resonance_1.0_10  latestcomp  \\\n",
       "docid                                                     \n",
       "nyp.33433074943634                 0.568580        1813   \n",
       "mdp.39015062084390                 1.698105        1955   \n",
       "uc2.ark+=13960=t3cz3334b           0.735204        1884   \n",
       "uva.x000380956                    -0.377158        1865   \n",
       "nyp.33433076030760                 0.192853        1844   \n",
       "inu.39000003707283                 0.923641        1892   \n",
       "uva.x000464259                     0.276871        1850   \n",
       "mdp.39015000695182                 1.325339        1972   \n",
       "uc2.ark+=13960=t1hh6d619           0.689373        1900   \n",
       "uc1.32106002103940                 0.794301        1952   \n",
       "mdp.39015066409924                 1.223019        1940   \n",
       "mdp.39015066065254                 0.632648        1973   \n",
       "dul1.ark+=13960=t98637h6g          1.485716        1895   \n",
       "inu.30000007102522                 0.868940        1925   \n",
       "nyp.33433074890454                -0.043819        1851   \n",
       "uc1.b4713109                       1.334026        1847   \n",
       "mdp.39015021862308                 0.437024        1977   \n",
       "mdp.39015031600409                 1.179059        1945   \n",
       "nyp.33433081852711                -0.494849        1882   \n",
       "mdp.39015004063601                 1.828535        1939   \n",
       "\n",
       "                                                  author  \n",
       "docid                                                     \n",
       "nyp.33433074943634                          Austen, Jane  \n",
       "mdp.39015062084390                     Nabokov, Vladimir  \n",
       "uc2.ark+=13960=t3cz3334b                     Twain, Mark  \n",
       "uva.x000380956                              Verne, Jules  \n",
       "nyp.33433076030760                      Poe, Edgar Allan  \n",
       "inu.39000003707283                   Doyle, Arthur Conan  \n",
       "uva.x000464259                      Hawthorne, Nathaniel  \n",
       "mdp.39015000695182                      Atwood, Margaret  \n",
       "uc2.ark+=13960=t1hh6d619               Dreiser, Theodore  \n",
       "uc1.32106002103940                        Ellison, Ralph  \n",
       "mdp.39015066409924                       Wright, Richard  \n",
       "mdp.39015066065254                       Pynchon, Thomas  \n",
       "dul1.ark+=13960=t98637h6g  Wells, H. G. (Herbert George)  \n",
       "inu.30000007102522                  Fitzgerald, F. Scott  \n",
       "nyp.33433074890454                      Melville, Herman  \n",
       "uc1.b4713109                           Bront, Charlotte  \n",
       "mdp.39015021862308                        Morrison, Toni  \n",
       "mdp.39015031600409                     Chandler, Raymond  \n",
       "nyp.33433081852711                          James, Henry  \n",
       "mdp.39015004063601                       Steinbeck, John  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prereg = meta.index[meta['preregistered'] == 1].tolist()\n",
    "special = zklddata.loc[prereg, ['resonance_1.0_25', 'resonance_0.05_40', 'resonance_1.0_10', 'latestcomp']]\n",
    "special = special.join(meta.author, how = 'inner')\n",
    "special"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vladimir Nabokov, Margaret Atwood, HG Wells, and Raymond Chandler are the champions of this round."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction with age\n",
    "\n",
    "The author's age at time of composition / publication is a very powerful factor in this dataset. It's worth considering how it interacts with other categories.\n",
    "\n",
    "Here we plot the author's age (at time of publication) on the x axis, the precocity of the work on y axis, and separate prominently reviewed authors (in blue) from randomly selected ones (in red)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join age to the data \n",
    "\n",
    "zklddata = zklddata.join(meta.age, how = 'inner')\n",
    "\n",
    "reviewed_docs = meta.index[meta.reviewed1850_1950 == 1].tolist()\n",
    "unreviewed_docs = meta.index[meta.reviewed1850_1950contrast == 1].tolist()\n",
    "\n",
    "reviewed_df = zklddata.loc[reviewed_docs, ['resonance_1.0_25', 'age']]\n",
    "unreviewed_df = zklddata.loc[unreviewed_docs, ['resonance_1.0_25', 'age']]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = reviewed_df.age\n",
    "y = reviewed_df['resonance_1.0_25']\n",
    "plt.scatter(x, y, c = 'b')\n",
    "x = x[~np.isnan(x) & ~np.isnan(y)]\n",
    "y = y[~np.isnan(y) & ~np.isnan(x)]\n",
    "z = np.polyfit(x, y, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(x,p(x),\"b--\")\n",
    "\n",
    "x = unreviewed_df.age\n",
    "y = unreviewed_df['resonance_1.0_25']\n",
    "plt.scatter(x, y, c = 'r', alpha = 0.6)\n",
    "x = x[~np.isnan(x) & ~np.isnan(y)]\n",
    "y = y[~np.isnan(y) & ~np.isnan(x)]\n",
    "z = np.polyfit(x, y, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(x,p(x),\"r--\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both factors matter. Reviewed authors have more precocity than unreviewed ones, at every age. But notice that any thirty-year-old author (even a randomly selected one) is likely to resemble the future more than any sixty-five-year-old one (even if famous)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
