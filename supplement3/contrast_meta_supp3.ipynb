{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble metadata for supplement 3\n",
    "\n",
    "This is going to be an annoyingly miscellaneous notebook, because this is a stage of the project where we're drawing on lots of different sources to slightly improve our metadata before the final interpretive push.\n",
    "\n",
    "To start with, a separate project has been manually correcting metadata for the NovelTM fiction corpus. This work was done by Jessica Witte, Patrick Kimutis, and Ted Underwood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use NovelTM metadata\n",
    "\n",
    "Import the tables generated by separate editors, and concatenate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jmc = pd.read_csv('../../meta2018/jessica.tsv', index_col = 'docid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmc = pd.read_csv('../../meta2018/patrick.tsv', index_col = 'docid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmc = pd.read_csv('../../meta2018/ted.tsv', sep = '\\t', index_col = 'docid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2730, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allmeta = pd.concat([tmc, jmc, pmc], sort = False)\n",
    "allmeta.to_csv('../../meta2018/merged/mergeddirectsample.tsv', sep = '\\t', index_label = 'docid')\n",
    "allmeta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually edit the data and read it back in\n",
    "\n",
    "There's a separate step here where Ted Underwood made some manual changes to the concatenated table, mostly involving the boundary separating \"reprint\" from \"novel.\"\n",
    "\n",
    "Then we read it back in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited = pd.read_csv('../../meta2018/merged/manuallyedited.tsv', sep = '\\t', index_col = 'docid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now read in the list of works we used for topic modeling\n",
    "\n",
    "Ideally, we might have corrected metadata before generating the topic model. But in reality I think that makes a tiny difference. We're not actually going to filter *out* many works at all; we're mostly changing the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "third = pd.read_csv('third_all_meta.tsv', sep = '\\t', index_col = 'docid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "third = third.assign(toremove = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to create a column to mark works I might remove, for generic reasons, if I do a fourth iteration of topic modeling. But these will  not actually be removed from the third model, because I don't want to get the corpus too far away from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "removenow = set()\n",
    "dateschanged = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A smaller number of works will be removed now (because their date makes them impossible to compare on our timeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corrections(existing, comparison):\n",
    "    ''' This function uses a comparison table to identify changes to the\n",
    "    \"existing\" table.\n",
    "    '''\n",
    "    \n",
    "    global removenow, dateschanged\n",
    "    \n",
    "    for idx, row in existing.iterrows():\n",
    "        if idx not in comparison.index:\n",
    "            continue\n",
    "        else:\n",
    "            if pd.isnull(comparison.loc[idx, 'firstpub']):\n",
    "                firstpub = 3000\n",
    "            else:\n",
    "                firstpub = int(comparison.loc[idx, 'firstpub'])\n",
    "            \n",
    "        if 'notfiction' in comparison.columns:\n",
    "            nonfic = comparison.loc[idx, 'notfiction']\n",
    "            if not pd.isnull(nonfic) and (nonfic == True or nonfic == 'TRUE'):\n",
    "                toremove = True\n",
    "            else:\n",
    "                toremove = False\n",
    "        elif 'category' in comparison.columns:\n",
    "            cat = comparison.loc[idx, 'category']\n",
    "            if not pd.isnull(cat) and (cat == 'nonfic' or cat == 'reprint' or cat == 'juvenile'):\n",
    "                toremove = True\n",
    "            else:\n",
    "                toremove = False\n",
    "        else:\n",
    "            toremove = False\n",
    "        \n",
    "        if toremove:\n",
    "            existing.loc[idx, 'toremove'] = True\n",
    "        \n",
    "        latestcomp = int(existing.loc[idx, 'latestcomp'])\n",
    "        \n",
    "        if firstpub < 1798:\n",
    "            removenow.add(idx)\n",
    "        elif firstpub < 1800:\n",
    "            existing.loc[idx, 'latestcomp'] = 1800\n",
    "            # we cheat a little around the margins to\n",
    "            # avoid removing more than needed\n",
    "            print(firstpub)\n",
    "            dateschanged += 1\n",
    "        elif firstpub < latestcomp:\n",
    "            existing.loc[idx, 'latestcomp'] = firstpub\n",
    "            dateschanged += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1799\n",
      "1799\n",
      "1799\n"
     ]
    }
   ],
   "source": [
    "make_corrections(third, edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dateschanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove now: 25\n",
      "Remove later: 181\n"
     ]
    }
   ],
   "source": [
    "print(\"Remove now:\", len(removenow))\n",
    "print(\"Remove later:\", sum(third.toremove))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting suspiciously old authors\n",
    "\n",
    "I also created a file of ```dates_to_correct.tsv``` where authors seemed suspiciously old. We can use this also to correct our third sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected = pd.read_csv('../meta/dates_to_correct.tsv', sep = '\\t', index_col = 'docid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1799\n",
      "Total dates changed: 280\n",
      "Remove now: 66\n",
      "Remove later: 212\n"
     ]
    }
   ],
   "source": [
    "make_corrections(third, corrected)\n",
    "print('Total dates changed:', dateschanged)\n",
    "print(\"Remove now:\", len(removenow))\n",
    "print(\"Remove later:\", sum(third.toremove))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting contrast sets\n",
    "\n",
    "For each of the hypotheses we're checking, we need a contrast set that is comparable in terms of genre / accuracy of dating / nationality. Let's construct them.\n",
    "\n",
    "First, let's construct a set of volumes that are accurately dated and exclude juvenile fiction and nonfiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_source = edited[(edited.category == 'novel') | (edited.category == 'shortstories')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2205, 17)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrast_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1037, 17)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared = contrast_source.loc[contrast_source.index.isin(third.index) , : ]\n",
    "shared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now load the hypotheses\n",
    "\n",
    "We need the list of volumes in the positive set for each hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2061, 22)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypo = pd.read_csv('third_hypothesis_meta.tsv', sep = '\\t', index_col = 'docid')\n",
    "hypo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create isusa columns in all our data\n",
    "\n",
    "This will make things simpler to check, since nationality is recorded in several different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed: 831\n",
      "US: 1118\n"
     ]
    }
   ],
   "source": [
    "hypo = hypo.assign(isusa = 0)\n",
    "\n",
    "changed = 0\n",
    "isus = 0\n",
    "\n",
    "for idx in hypo.index:\n",
    "    if pd.isnull(hypo.loc[idx, 'nationality']):\n",
    "        hypo.loc[idx, 'nationality'] = third.loc[idx, 'nationality']\n",
    "        changed += 1\n",
    "    \n",
    "    nation = hypo.loc[idx, 'nationality']\n",
    "    if nation.strip() =='us' or nation.strip() == \"guess: us\":\n",
    "        hypo.loc[idx, 'isusa'] = 1\n",
    "        isus += 1\n",
    "        \n",
    "print('Changed:', changed)\n",
    "print('US:', isus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed: 156\n",
      "US: 279\n"
     ]
    }
   ],
   "source": [
    "shared = shared.assign(isusa = 0)\n",
    "isus = 0\n",
    "changed = 0\n",
    "\n",
    "for idx in shared.index:\n",
    "    nation = shared.loc[idx, 'nationality']\n",
    "    if pd.isnull(nation):\n",
    "        shared.loc[idx, 'nationality'] = third.loc[idx, 'nationality']\n",
    "        nation = shared.loc[idx, 'nationality']\n",
    "        \n",
    "    if nation.strip() =='us' or nation.strip() == \"guess: us\":\n",
    "        shared.loc[idx, 'isusa'] = 1\n",
    "        isus += 1\n",
    "    \n",
    "    firstpub = shared.loc[idx, 'firstpub']\n",
    "    if not pd.isnull(firstpub):\n",
    "        firstpub = int(firstpub)\n",
    "        if firstpub < shared.loc[idx, 'latestcomp']:\n",
    "            shared.loc[idx, 'latestcomp'] = firstpub\n",
    "            changed += 1\n",
    "        \n",
    "print('Changed:', changed)        \n",
    "print('US:', isus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US: 18148\n"
     ]
    }
   ],
   "source": [
    "def whether_us(nation):\n",
    "    if nation.strip() =='us' or nation.strip() == \"guess: us\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "third = third.assign(isusa = third.nationality.map(whether_us))\n",
    "               \n",
    "print('US:', sum(third.isusa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39850, 15)\n",
      "(39784, 15)\n"
     ]
    }
   ],
   "source": [
    "print(third.shape)\n",
    "third.drop(removenow, inplace = True)\n",
    "print(third.shape)\n",
    "third.to_csv('third_corrected_meta.tsv', sep = '\\t', index_label = 'docid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194, 16)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manualcheck = pd.read_csv('manualcheckus.tsv', sep = '\\t')\n",
    "manualcheck.drop_duplicates('docid', inplace = True)\n",
    "manualcheck.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "manualcheck = manualcheck.set_index('docid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correction\n",
      "correction\n",
      "correction\n"
     ]
    }
   ],
   "source": [
    "for idx, row in manualcheck.iterrows():\n",
    "    wehave = third.loc[idx, 'latestcomp']\n",
    "    groundtruth = manualcheck.loc[idx, 'latestcomp']\n",
    "    if groundtruth < wehave:\n",
    "        print('correction')\n",
    "        third.loc[idx, 'latestcomp'] = groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US: 87\n"
     ]
    }
   ],
   "source": [
    "manualcheck = manualcheck.assign(isusa = manualcheck.nationality.map(whether_us))\n",
    "               \n",
    "print('US:', sum(manualcheck.isusa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "manualcheck.to_csv('manualcheckus.tsv', sep = '\\t', index_label = 'docid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyposelected = dict()\n",
    "contrast = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2061, 23)\n",
      "(1037, 18)\n",
      "(39784, 36)\n"
     ]
    }
   ],
   "source": [
    "print(hypo.shape)\n",
    "print(shared.shape)\n",
    "print(third.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(hypo, manually_checked, third, category, startdate, enddate):\n",
    "    ''' Finds volumes in manually_checked that match the nationality and\n",
    "    date distribution of volumes in category.\n",
    "    '''\n",
    "    global contrast, hyposelected\n",
    "    \n",
    "    subset = hypo.loc[(hypo[category] == True) &\n",
    "                      (hypo.latestcomp >= startdate) &\n",
    "                      (hypo.latestcomp < enddate), : ]\n",
    "    \n",
    "    contrast[(category, startdate)] = []\n",
    "    hyposelected[(category, startdate)] = []\n",
    "    \n",
    "    print(\"Needed: \", subset.shape)\n",
    "    \n",
    "    # The contrast set is defined to exclude books\n",
    "    # by authors in the positive set.\n",
    "    hypo_authors = set(subset.author)\n",
    "    \n",
    "    available = manually_checked.loc[~manually_checked['author'].isin(hypo_authors), : ]\n",
    "    \n",
    "    print(\"Available: \", available.shape)\n",
    "    already_chosen = set()\n",
    "    \n",
    "    # shuffle the subset\n",
    "    subset = subset.sample(frac = 1)\n",
    "    \n",
    "    secondary = 0\n",
    "    \n",
    "    for idx, row in subset.iterrows():\n",
    "        if len(already_chosen) > 140:\n",
    "            break\n",
    "            \n",
    "        usflag = row['isusa']\n",
    "        date = row['latestcomp']\n",
    "        \n",
    "        candidates = available.loc[(available.isusa == usflag) & \n",
    "                                   (available.latestcomp > (date - 4)) &\n",
    "                                   (available.latestcomp < (date + 4)), : ]\n",
    "        candidates = candidates.index.tolist()\n",
    "        candidates = set(candidates) - already_chosen\n",
    "        \n",
    "        if len(candidates) < 1:\n",
    "            failures[category] += 1\n",
    "            thirdoptions = third.loc[(third.isusa == usflag) &\n",
    "                                    (third.latestcomp > (date - 4)) &\n",
    "                                    (third.latestcomp < (date + 4)), : ]\n",
    "            thirdoptions = thirdoptions.loc[~thirdoptions['author'].isin(hypo_authors), : ]\n",
    "            thirdoptions = thirdoptions.index.tolist()\n",
    "            thirdoptions = set(thirdoptions) - already_chosen\n",
    "            \n",
    "            if len(thirdoptions) < 1:\n",
    "                print(\"Unrecoverable error.\")\n",
    "            else:\n",
    "                selection = random.sample(thirdoptions, 1)[0]\n",
    "                contrast[(category, startdate)].append(selection)\n",
    "                already_chosen.add(selection)\n",
    "                hyposelected[(category, startdate)].append(idx)\n",
    "                secondary += 1\n",
    "                  \n",
    "        else:\n",
    "            selection = random.sample(candidates, 1)[0]\n",
    "            contrast[(category, startdate)].append(selection)\n",
    "            already_chosen.add(selection)\n",
    "            hyposelected[(category, startdate)].append(idx)\n",
    "            \n",
    "    print(\"Found: \", len(contrast[(category, startdate)]))\n",
    "    print(\"Secondary: \", secondary)\n",
    "    \n",
    "    return contrast[(category, startdate)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needed:  (141, 23)\n",
      "Available:  (1034, 18)\n",
      "Unrecoverable error.\n",
      "Unrecoverable error.\n",
      "Found:  139\n",
      "Secondary:  15\n"
     ]
    }
   ],
   "source": [
    "selections = find_matches(hypo, shared, manualcheck, 'bestseller', 1821, 1900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needed:  (414, 23)\n",
      "Available:  (1024, 18)\n",
      "Unrecoverable error.\n",
      "Unrecoverable error.\n",
      "Found:  141\n",
      "Secondary:  33\n"
     ]
    }
   ],
   "source": [
    "selections = find_matches(hypo, shared, manualcheck, 'bestseller', 1900, 1950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needed:  (181, 23)\n",
      "Available:  (1031, 18)\n",
      "Found:  141\n",
      "Secondary:  66\n"
     ]
    }
   ],
   "source": [
    "selections = find_matches(hypo, shared, manualcheck, 'bestseller', 1950, 1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bestseller', 1950) 141\n",
      "('bestseller', 1900) 141\n",
      "('bestseller', 1821) 139\n"
     ]
    }
   ],
   "source": [
    "for k, v in hyposelected.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needed:  (46, 23)\n",
      "Available:  (1025, 18)\n",
      "Found:  46\n",
      "Secondary:  0\n"
     ]
    }
   ],
   "source": [
    "selections = find_matches(hypo, shared, manualcheck, 'heath', 1800, 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needed:  (54, 23)\n",
      "Available:  (1028, 18)\n",
      "Found:  54\n",
      "Secondary:  1\n"
     ]
    }
   ],
   "source": [
    "selections = find_matches(hypo, shared, manualcheck, 'norton', 1800, 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needed:  (5, 23)\n",
      "Available:  (1037, 18)\n",
      "Found:  5\n",
      "Secondary:  0\n"
     ]
    }
   ],
   "source": [
    "selections = find_matches(hypo, shared, manualcheck, 'nortonshort', 1800, 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(hypo.nortonshort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needed:  (55, 23)\n",
      "Available:  (1025, 18)\n",
      "Found:  55\n",
      "Secondary:  0\n"
     ]
    }
   ],
   "source": [
    "selections = find_matches(hypo, shared, manualcheck, 'nonusnorton', 1800, 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needed:  (20, 23)\n",
      "Available:  (1028, 18)\n",
      "Found:  20\n",
      "Secondary:  0\n"
     ]
    }
   ],
   "source": [
    "selections = find_matches(hypo, shared, manualcheck, 'preregistered', 1800, 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needed:  (29, 23)\n",
      "Available:  (1032, 18)\n",
      "Found:  29\n",
      "Secondary:  0\n"
     ]
    }
   ],
   "source": [
    "selections = find_matches(hypo, shared, manualcheck, 'mostdiscussed', 1800, 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['allcopiesofwork', 'author', 'bestseller', 'contrast4reviewed',\n",
       "       'copiesin25yrs', 'earlyedition', 'firstpub', 'gender', 'heath',\n",
       "       'imprint', 'inferreddate', 'lastname', 'latestcomp', 'mostdiscussed',\n",
       "       'nationality', 'nonusnorton', 'norton', 'nortonshort', 'preregistered',\n",
       "       'recordid', 'reviewed', 'title', 'isusa'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39784, 36)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['allcopiesofwork', 'author', 'copiesin25yrs', 'earlyedition', 'imprint',\n",
       "       'inferreddate', 'lastname', 'latestcomp', 'nationality', 'recordid',\n",
       "       'title', 'authordate', 'birth', 'toremove', 'isusa', 'best1821_1900',\n",
       "       'best1900_1950', 'best1950_1990', 'anybest', 'best1821_1900contrast',\n",
       "       'best1900_1950contrast', 'best1950_1990contrast', 'reviewed1850_1950',\n",
       "       'reviewed1850_1950contrast', 'heath', 'heathcontrast', 'mostdiscussed',\n",
       "       'mostdiscussedcontrast', 'usnorton', 'usnortoncontrast', 'nonusnorton',\n",
       "       'nonusnortoncontrast', 'preregistered', 'preregisteredcontrast',\n",
       "       'reviewed1965_1990', 'reviewed1965_1990contrast'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third = third.assign(best1821_1900 = 0)\n",
    "third = third.assign(best1900_1950 = 0)\n",
    "third = third.assign(best1950_1990 = 0)\n",
    "third = third.assign(anybest = 0)\n",
    "third = third.assign(best1821_1900contrast = 0)\n",
    "third = third.assign(best1900_1950contrast = 0)\n",
    "third = third.assign(best1950_1990contrast = 0)\n",
    "third = third.assign(best1900_1950 = 0)\n",
    "third = third.assign(reviewed1850_1950 = 0)\n",
    "third = third.assign(reviewed1850_1950contrast = 0)\n",
    "third = third.assign(heath = 0)\n",
    "third = third.assign(heathcontrast = 0)\n",
    "third = third.assign(mostdiscussed = 0)\n",
    "third = third.assign(mostdiscussedcontrast = 0)\n",
    "third = third.assign(usnorton = 0)\n",
    "third = third.assign(usnortoncontrast = 0)\n",
    "third = third.assign(nonusnorton = 0)\n",
    "third = third.assign(nonusnortoncontrast = 0)\n",
    "third = third.assign(preregistered = 0)\n",
    "third = third.assign(preregisteredcontrast = 0)\n",
    "third = third.assign(reviewed1965_1990 = 0)\n",
    "third = third.assign(reviewed1965_1990contrast = 0)\n",
    "print(third.shape)\n",
    "third.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostreviewedpost65 = pd.read_csv('../meta/canon/mostreviewedpost65.tsv', sep = '\\t', index_col = 'docid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dict = {'best1821_1900': ('bestseller', 1821),\n",
    " 'best1900_1950': ('bestseller', 1900),\n",
    " 'best1950_1990': ('bestseller', 1950),\n",
    " 'best1900_1950contrast': ('bestseller', 1950),\n",
    " 'best1950_1990contrast': ('bestseller', 1900),\n",
    " 'best1821_1900contrast': ('bestseller', 1821),\n",
    " 'heath': ('heath', 1800),\n",
    " 'heathcontrast': ('heath', 1800),\n",
    " 'mostdiscussed': ('mostdiscussed', 1800),\n",
    " 'mostdiscussedcontrast': ('mostdiscussed', 1800),\n",
    " 'usnorton': ('norton', 1800),\n",
    " 'usnortoncontrast': ('norton', 1800),\n",
    " 'nonusnorton': ('nonusnorton', 1800),\n",
    " 'nonusnortoncontrast': ('nonusnorton', 1800),\n",
    " 'preregistered': ('preregistered', 1800),\n",
    " 'preregisteredcontrast': ('preregistered', 1800)}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mostdiscussed 29\n",
      "best1950_1990contrast 141\n",
      "best1950_1990 141\n",
      "usnortoncontrast 54\n",
      "mostdiscussedcontrast 29\n",
      "best1821_1900contrast 139\n",
      "nonusnorton 55\n",
      "preregistered 20\n",
      "heathcontrast 46\n",
      "best1900_1950contrast 141\n",
      "usnorton 54\n",
      "best1821_1900 139\n",
      "best1900_1950 141\n",
      "preregisteredcontrast 20\n",
      "heath 46\n",
      "nonusnortoncontrast 55\n"
     ]
    }
   ],
   "source": [
    "for key, value in category_dict.items():\n",
    "    ctr = 0\n",
    "    \n",
    "    if 'contrast' in key:\n",
    "        volstoadd = contrast[value]\n",
    "    else:\n",
    "        volstoadd = hyposelected[value]\n",
    "    \n",
    "    for vol in volstoadd:\n",
    "        third.loc[vol, key] = 1\n",
    "        ctr +=1\n",
    "    \n",
    "    print(key, ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in mostreviewedpost65.index:\n",
    "    third.loc[idx, 'reviewed1965_1990'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "for idx in hyposelected[('nortonshort', 1800)]:\n",
    "    third.loc[idx, 'usnorton'] = 1\n",
    "    ctr +=1\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "for idx in contrast[('nortonshort', 1800)]:\n",
    "    third.loc[idx, 'usnortoncontrast'] = 1\n",
    "    ctr +=1\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541\n"
     ]
    }
   ],
   "source": [
    "third = third.assign(reviewed1965_1990 = 0)\n",
    "third = third.assign(reviewed1965_1990contrast = 0)\n",
    "ctr = 0\n",
    "for idx in hypo.loc[hypo.reviewed == True, : ].index:\n",
    "    third.loc[idx, 'reviewed1850_1950'] = 1\n",
    "    ctr += 1\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "for idx in hypo.loc[hypo.contrast4reviewed == True, : ].index:\n",
    "    third.loc[idx, 'reviewed1850_1950contrast'] = 1\n",
    "    ctr += 1\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "for idx in hypo.loc[hypo.bestseller == True, : ].index:\n",
    "    third.loc[idx, 'anybest'] = 1\n",
    "    ctr += 1\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770-1844. nan\n",
      "1802-1887. nan\n",
      "1770-1844. nan\n",
      "1807-1876. -1824\n",
      "1770-1844. nan\n",
      "1930-. 1897-\n"
     ]
    }
   ],
   "source": [
    "for idx, row in corrected.iterrows():\n",
    "    if idx not in third.index:\n",
    "        continue\n",
    "    else:\n",
    "        groundtruth = row['authordate']\n",
    "        existing = third.loc[idx, 'authordate']\n",
    "        if pd.isnull(groundtruth):\n",
    "            continue\n",
    "        else:\n",
    "            groundlen = len(str(groundtruth))\n",
    "            \n",
    "        if pd.isnull(existing):\n",
    "            existlen = 0\n",
    "        else:\n",
    "            existlen = len(str(existing))\n",
    "        \n",
    "        if groundlen > existlen:\n",
    "            print(groundtruth, existing)\n",
    "            third.loc[idx, 'authordate'] = groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770-1844. nan\n",
      "1899-1982. nan\n",
      "1912- nan\n",
      "1824-1906 nan\n",
      "1822-1911 nan\n",
      "1708-1778 nan\n",
      "1798-1866 nan\n",
      "1798-1857. nan\n",
      "1892-1990 1892-\n",
      "1922-1998. nan\n",
      "1924-2008. 1924-\n",
      "1748-1828. nan\n",
      "1695-1758 nan\n",
      "1758-1852 nan\n",
      "1775-1842 nan\n",
      "1757-1807 b. 1756.\n",
      "1759-1805. nan\n",
      "1759-1805. nan\n",
      "1774-1815 nan\n",
      "1770-1847 nan\n",
      "1770-1847. nan\n",
      "1770-1847. nan\n",
      "f. 1827 nan\n",
      "1763-1822. nan\n",
      "1758-1852 nan\n",
      "d. 1827 nan\n",
      "1759-1857. nan\n",
      "1775-1842. nan\n",
      "1759-1857. nan\n",
      "1759-1857. nan\n",
      "d. 1849 nan\n",
      "1779-1859 nan\n",
      "1779-1846 nan\n",
      "1779-1859. nan\n",
      "1779-1859. nan\n",
      "1758-1852. nan\n",
      "1788-1869. d. 1869.\n",
      "1790-1860. nan\n",
      "1791-1854. nan\n",
      "1779-1859 nan\n",
      "1746-1830. nan\n",
      "1787-1867 nan\n",
      "1776-1865. nan\n",
      "1775-1842. nan\n",
      "1786-1820 nan\n",
      "1785-1828. nan\n",
      "1761-1826. d. 1818.\n",
      "1772-1825. nan\n",
      "1768-1842. nan\n",
      "1784?-1854. d. 1854.\n",
      "1800-1842 nan\n",
      "1800-1842. nan\n",
      "1798-1861. nan\n",
      "1805-1844 nan\n",
      "1806-1844 nan\n",
      "1806-1844. nan\n",
      "1800-1851. nan\n",
      "1798-1861 nan\n",
      "1804-1867 nan\n",
      "1792-1838. nan\n",
      "d. 1875 nan\n",
      "1778-1845. d. 1845.\n",
      "1806-1862. nan\n",
      "1806-1862. nan\n",
      "1801-1843. d. 1843.\n",
      "1801-1843 d. 1843.\n",
      "1798-1869 nan\n",
      "1816-1870 nan\n",
      "1788-1856 nan\n",
      "1798-1861. nan\n",
      "1802-1882 nan\n",
      "1801-1843 d. 1843.\n",
      "1814-1900 nan\n",
      "1812-1885 nan\n",
      "1811-1854 nan\n",
      "1827-1856 nan\n",
      "1820-1877. nan\n",
      "1801-1886. nan\n",
      "1807-1893 nan\n",
      "1807-1893. nan\n",
      "1805-1875. nan\n",
      "1784-1857 nan\n",
      "1828-1891 nan\n",
      "1826-1895. nan\n",
      "1777-1843 nan\n",
      "1836-1919. nan\n",
      "1828-1865 nan\n",
      "1828-1897. nan\n",
      "1835-1914 nan\n",
      "1841-1920 d. 1914.\n",
      "1811-1891 nan\n",
      "1831-1896 b. 1831.\n",
      "1836-1897. nan\n",
      "1819-1894 nan\n",
      "1844-1922. nan\n",
      "1833-1909 nan\n",
      "1814-1884 | 1820-1890 1814-1884.\n",
      "1829-1900. nan\n",
      "1847-1918 nan\n",
      "1839-1909 b. 1839.\n",
      "1844-1936 nan\n",
      "1850-1912 b. 1850.\n",
      "1849-1925. nan\n",
      "1850-1928. b. 1850.\n",
      "1847-1933. nan\n",
      "1841-1914 b. 1841.\n",
      "1845-1912. nan\n",
      "1851-1904 nan\n",
      "1865-1965 nan\n",
      "1841-1905 nan\n",
      "1870-1937 nan\n",
      "1866-1959 1865-\n",
      "1889-1951 nan\n",
      "1792-1875 nan\n",
      "1864-1925. nan\n",
      "1852-1921. nan\n",
      "1862-1919. 1862-\n",
      "1862-1931 d. 1931.\n",
      "1888-1965. nan\n",
      "1898-1982. 1898-\n",
      "1854-1938. 1854-\n",
      "1885-1958. 1885-\n",
      "1877-1971 b. 1877.\n",
      "d. 1949 nan\n",
      "1870-1951 1870-\n",
      "1895-1981 1895-\n",
      "1914-2000. 1880-1959\n",
      "1909-1989 1909-\n",
      "1904-1998. 1904-\n",
      "1906-1957 1906-\n",
      "1897-1993 1897-\n",
      "1880-1943. nan\n",
      "1909-1999. 1909-\n",
      "1910-1997. nan\n",
      "1906-1980. 1906-\n",
      "1911-1988 nan\n",
      "b. 1917 nan\n",
      "b. 1915-  nan\n",
      "1901-1984. 1901-\n",
      "1915-1983 nan\n",
      "1928-2000 nan\n",
      "1915-2001. 1915-\n",
      "1924-2005 nan\n",
      "1933- nan\n",
      "1922-1998. nan\n",
      "1919-2016 1919-\n",
      "1912-1997. nan\n",
      "1935-1984 nan\n",
      "1892-1975. 1892-\n",
      "1929-2009. nan\n",
      "1931- nan\n",
      "1939- nan\n",
      "b. 1941 nan\n",
      "1919-1995 nan\n",
      "1935- nan\n",
      "b. 1927 nan\n",
      "1927-2013. 1927-\n",
      "(1928)- nan\n",
      "1941-2009 nan\n",
      "b. 1940 nan\n",
      "b. 1931 nan\n",
      "1907-2002 nan\n",
      "b. 1939 nan\n",
      "1935- nan\n",
      "1949-1995 nan\n",
      "1925-1990 nan\n",
      "1924-2007 nan\n",
      "1933-2018 nan\n",
      "b.1941 nan\n",
      "1949- nan\n",
      "b. 1945 nan\n",
      "1937-1995 | b. 1948 1937-\n",
      "1960- nan\n",
      "b. 1936 nan\n",
      "b. 1952. nan\n",
      "1919- nan\n",
      "1968- nan\n",
      "b. 1957 nan\n",
      "b. 1964 nan\n",
      "1948- nan\n",
      "b. 1977 nan\n",
      "b. 1931 nan\n",
      "1955- nan\n",
      "1921-1996. nan\n",
      "1687-c. 1750 nan\n",
      "1770-1844. nan\n",
      "1920-2003 nan\n",
      "1914-1999 nan\n",
      "1792-1875 nan\n",
      "1791-1860. nan\n",
      "1798-1856. d. 1856.\n",
      "1824-1917 nan\n",
      "1915-2001 nan\n",
      "1905-1968 1905-\n",
      "1937-1987. nan\n",
      "1924-2008 nan\n",
      "1920-2008. nan\n",
      "1943- nan\n",
      "1947- nan\n",
      "1808-1908. nan\n"
     ]
    }
   ],
   "source": [
    "for idx, row in edited.iterrows():\n",
    "    if idx not in third.index:\n",
    "        continue\n",
    "    else:\n",
    "        groundtruth = row['authordate']\n",
    "        existing = third.loc[idx, 'authordate']\n",
    "        if pd.isnull(groundtruth):\n",
    "            continue\n",
    "        else:\n",
    "            groundlen = len(str(groundtruth))\n",
    "            \n",
    "        if pd.isnull(existing):\n",
    "            existlen = 0\n",
    "        else:\n",
    "            existlen = len(str(existing))\n",
    "        \n",
    "        if groundlen > existlen:\n",
    "            print(groundtruth, existing)\n",
    "            third.loc[idx, 'authordate'] = groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "third = third.assign(age = float('nan'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23826\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "\n",
    "def calculate_age(row):\n",
    "    global ctr\n",
    "    if pd.isnull(row['authordate']):\n",
    "        return float('nan')\n",
    "    else:\n",
    "        dates = str(row['authordate'].strip('.'))\n",
    "        \n",
    "    if dates.startswith('b.') or dates.endswith('-') or len(dates) > 7:\n",
    "        try:\n",
    "            birth = int(dates[0:4])\n",
    "        except:\n",
    "            birth = -1\n",
    "    else:\n",
    "        birth = -1\n",
    "    \n",
    "    compdate = int(row['latestcomp'])\n",
    "    \n",
    "    if birth > 0 and birth < compdate:\n",
    "        age = compdate - birth\n",
    "        if age > 100:\n",
    "            return(float('nan'))\n",
    "        else:\n",
    "            ctr += 1\n",
    "            return age\n",
    "    else:\n",
    "        return float('nan')\n",
    "\n",
    "third = third.assign(age = third.apply(calculate_age, axis = 1))\n",
    "print(ctr)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "third = third.assign(actualgender = float('nan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "for idx, row in edited.iterrows():\n",
    "    if idx not in third.index:\n",
    "        continue\n",
    "    else:\n",
    "        gender = row['gender']\n",
    "        if not pd.isnull(gender):\n",
    "            third.loc[idx, 'actualgender'] = row['gender']\n",
    "            ctr += 1\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "for idx, row in hypo.iterrows():\n",
    "    if idx not in third.index:\n",
    "        continue\n",
    "    else:\n",
    "        gender = row['gender']\n",
    "        if not pd.isnull(gender):\n",
    "            third.loc[idx, 'actualgender'] = row['gender']\n",
    "            ctr += 1\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39784, 38)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirdtogender = third[['author', 'latestcomp', 'actualgender']]\n",
    "thirdtogender.to_csv('third2gender.tsv', sep = '\\t', index_label = 'docid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "gendered = pd.read_csv('thirdgendered.tsv', sep = '\\t', index_col = 'docid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "third = third.assign(likelygender = float('nan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1001\n",
      "2001\n",
      "3001\n",
      "4001\n",
      "5001\n",
      "6001\n",
      "7001\n",
      "8001\n",
      "9001\n",
      "10001\n",
      "11001\n",
      "12001\n",
      "13001\n",
      "14001\n",
      "15001\n",
      "16001\n",
      "17001\n",
      "18001\n",
      "19001\n",
      "20001\n",
      "21001\n",
      "22001\n",
      "23001\n",
      "24001\n",
      "25001\n",
      "26001\n",
      "27001\n",
      "28001\n",
      "29001\n",
      "30001\n",
      "31001\n",
      "32001\n",
      "33001\n",
      "34001\n",
      "35001\n",
      "36001\n",
      "37001\n",
      "38001\n",
      "39001\n",
      "Right:  1406\n",
      "Wrong:  79\n"
     ]
    }
   ],
   "source": [
    "right = 0\n",
    "wrong = 0\n",
    "ctr = 0\n",
    "\n",
    "for idx, row in gendered.iterrows():\n",
    "    ctr += 1\n",
    "    if ctr % 1000 == 1:\n",
    "        print(ctr)\n",
    "        \n",
    "    actual = third.loc[idx, 'actualgender']\n",
    "    predicted = row.Gender.lower()\n",
    "    if predicted == 'u':\n",
    "        predicted = np.nan\n",
    "        \n",
    "    if pd.isnull(actual):\n",
    "        third.loc[idx, 'likelygender'] = predicted\n",
    "    else:\n",
    "        if actual == predicted:\n",
    "            right += 1\n",
    "            third.loc[idx, 'likelygender'] = actual\n",
    "        elif pd.isnull(predicted):\n",
    "            third.loc[idx, 'likelygender'] = actual\n",
    "            continue\n",
    "        else:\n",
    "            wrong += 1\n",
    "            third.loc[idx, 'likelygender'] = actual\n",
    "\n",
    "print(\"Right: \", right)\n",
    "print(\"Wrong: \", wrong)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not terrible accuracy, so likelygender column is probably okay to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 1778\n",
      "nan 1748\n",
      "nan 1925\n",
      "nan 1956\n",
      "nan 1786\n",
      "nan 1844\n",
      "nan 1833\n",
      "nan 1791\n",
      "nan 1968\n",
      "1865.0 1866\n",
      "nan 1915\n",
      "nan 1759\n",
      "nan 1935\n",
      "nan 1770\n",
      "nan 1770\n",
      "nan 1828\n",
      "nan 1847\n",
      "nan 1925\n",
      "nan 1822\n",
      "nan 1925\n",
      "1880.0 1914\n",
      "nan 1775\n",
      "nan 1925\n",
      "nan 1779\n",
      "nan 1779\n",
      "nan 1708\n",
      "nan 1865\n",
      "nan 1770\n",
      "nan 1852\n",
      "nan 1925\n",
      "nan 1770\n",
      "nan 1839\n",
      "nan 1806\n",
      "nan 1925\n",
      "nan 1912\n",
      "nan 1828\n",
      "nan 1758\n",
      "nan 1787\n",
      "nan 1925\n",
      "nan 1819\n",
      "nan 1763\n",
      "nan 1922\n",
      "nan 1798\n",
      "1897.0 1930\n",
      "nan 1779\n",
      "nan 1758\n",
      "nan 1899\n",
      "nan 1798\n",
      "nan 1807\n",
      "nan 1891\n",
      "nan 1824\n",
      "nan 1949\n",
      "nan 1785\n",
      "nan 1812\n",
      "nan 1798\n",
      "nan 1805\n",
      "nan 1841\n",
      "nan 1907\n",
      "nan 1935\n",
      "nan 1931\n",
      "nan 1770\n",
      "nan 1921\n",
      "nan 1836\n",
      "nan 1814\n",
      "nan 1777\n",
      "nan 1910\n",
      "nan 1792\n",
      "nan 1808\n",
      "nan 1941\n",
      "nan 1841\n",
      "nan 1851\n",
      "nan 1779\n",
      "nan 1928\n",
      "nan 1915\n",
      "nan 1802\n",
      "nan 1759\n",
      "nan 1915\n",
      "nan 1900\n",
      "nan 1933\n",
      "nan 1827\n",
      "nan 1791\n",
      "nan 1880\n",
      "nan 1801\n",
      "nan 1784\n",
      "nan 1758\n",
      "nan 1937\n",
      "nan 1806\n",
      "nan 1772\n",
      "nan 1847\n",
      "nan 1911\n",
      "nan 1845\n",
      "nan 1779\n",
      "nan 1790\n",
      "nan 1798\n",
      "nan 1862\n",
      "nan 1932\n",
      "nan 1955\n",
      "nan 1816\n",
      "nan 1788\n",
      "nan 1949\n",
      "nan 1768\n",
      "nan 1829\n",
      "nan 1919\n",
      "nan 1759\n",
      "nan 1925\n",
      "nan 1807\n",
      "nan 1798\n",
      "nan 1695\n",
      "nan 1807\n",
      "nan 1889\n",
      "nan 1804\n",
      "nan 1805\n",
      "nan 1800\n",
      "nan 1776\n",
      "nan 1919\n",
      "nan 1806\n",
      "nan 1872\n",
      "nan 1956\n",
      "nan 1924\n",
      "nan 1933\n",
      "nan 1850\n",
      "nan 1831\n",
      "nan 1925\n",
      "nan 1806\n",
      "nan 1941\n",
      "nan 1841\n",
      "nan 1836\n",
      "nan 1800\n",
      "nan 1774\n",
      "nan 1802\n",
      "nan 1960\n",
      "nan 1948\n",
      "nan 1811\n",
      "nan 1746\n",
      "nan 1800\n",
      "nan 1811\n",
      "nan 1927\n",
      "nan 1761\n",
      "nan 1759\n",
      "nan 1939\n",
      "nan 1924\n",
      "nan 1798\n",
      "nan 1849\n",
      "nan 1877\n",
      "nan 1788\n",
      "nan 1887\n",
      "nan 1935\n",
      "nan 1801\n",
      "nan 1912\n",
      "nan 1914\n",
      "nan 1784\n",
      "nan 1798\n",
      "nan 1757\n",
      "nan 1888\n",
      "nan 1929\n",
      "nan 1826\n",
      "nan 1922\n",
      "nan 1687\n",
      "nan 1864\n",
      "nan 1820\n",
      "nan 1943\n",
      "nan 1920\n",
      "nan 1904\n",
      "nan 1801\n",
      "nan 1925\n",
      "nan 1775\n",
      "nan 1828\n",
      "nan 1835\n",
      "nan 1844\n",
      "nan 1947\n",
      "nan 1792\n",
      "nan 1925\n",
      "nan 1770\n",
      "nan 1792\n",
      "nan 1759\n",
      "nan 1770\n",
      "nan 1824\n",
      "nan 1925\n",
      "nan 1775\n",
      "nan 1770\n",
      "nan 1870\n",
      "nan 1801\n",
      "nan 1924\n",
      "nan 1920\n",
      "nan 1850\n",
      "185\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "\n",
    "def calculate_birth(row):\n",
    "    global ctr\n",
    "    existingbirth = row['birth']\n",
    "    \n",
    "    if pd.isnull(row['authordate']):\n",
    "        return existingbirth\n",
    "    else:\n",
    "        dates = str(row['authordate'].strip('.'))\n",
    "        \n",
    "    if dates.startswith('b.') or dates.endswith('-') or len(dates) > 7:\n",
    "        try:\n",
    "            birth = int(dates[0:4])\n",
    "        except:\n",
    "            birth = -1\n",
    "    else:\n",
    "        birth = -1\n",
    "    \n",
    "    if birth > 0 and birth < 2010:\n",
    "        if birth != existingbirth:\n",
    "            ctr += 1\n",
    "            print(existingbirth, birth)\n",
    "        \n",
    "        return birth\n",
    "\n",
    "    else:\n",
    "        return existingbirth\n",
    "\n",
    "third = third.assign(birth = third.apply(calculate_birth, axis = 1))\n",
    "print(ctr)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['allcopiesofwork', 'author', 'copiesin25yrs', 'earlyedition', 'imprint',\n",
       "       'inferreddate', 'lastname', 'latestcomp', 'nationality', 'recordid',\n",
       "       'title', 'authordate', 'birth', 'toremove', 'isusa', 'best1821_1900',\n",
       "       'best1900_1950', 'best1950_1990', 'anybest', 'best1821_1900contrast',\n",
       "       'best1900_1950contrast', 'best1950_1990contrast', 'reviewed1850_1950',\n",
       "       'reviewed1850_1950contrast', 'heath', 'heathcontrast', 'mostdiscussed',\n",
       "       'mostdiscussedcontrast', 'usnorton', 'usnortoncontrast', 'nonusnorton',\n",
       "       'nonusnortoncontrast', 'preregistered', 'preregisteredcontrast',\n",
       "       'reviewed1965_1990', 'reviewed1965_1990contrast', 'age', 'actualgender',\n",
       "       'likelygender'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "rightorder = ['allcopiesofwork', 'author', 'copiesin25yrs', 'earlyedition', 'imprint',\n",
    "       'inferreddate', 'lastname', 'latestcomp', 'nationality', 'isusa', 'actualgender',\n",
    "       'likelygender', 'title', 'authordate', 'birth', 'age', 'recordid', 'best1821_1900',\n",
    "       'best1900_1950', 'best1950_1990', 'anybest', 'best1821_1900contrast',\n",
    "       'best1900_1950contrast', 'best1950_1990contrast', 'reviewed1850_1950',\n",
    "       'reviewed1850_1950contrast', 'heath', 'heathcontrast', 'mostdiscussed',\n",
    "       'mostdiscussedcontrast', 'usnorton', 'usnortoncontrast', 'nonusnorton',\n",
    "       'nonusnortoncontrast', 'preregistered', 'preregisteredcontrast',\n",
    "       'reviewed1965_1990', 'reviewed1965_1990contrast', 'toremove']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "third = third[rightorder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Needed:  (100, 39)\n",
      "Available:  (1030, 18)\n",
      "Unrecoverable error.\n",
      "Unrecoverable error.\n",
      "Unrecoverable error.\n",
      "Unrecoverable error.\n",
      "Unrecoverable error.\n",
      "Found:  95\n",
      "Secondary:  53\n"
     ]
    }
   ],
   "source": [
    "selections = find_matches(third, shared, manualcheck, 'reviewed1965_1990', 1950, 2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sel in selections:\n",
    "    third.loc[sel, 'reviewed1965_1990contrast'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "third.to_csv('thirdmastermeta.tsv', sep = '\\t', index_label = 'docid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2check = ['best1821_1900',\n",
    "       'best1900_1950', 'best1950_1990', 'anybest', 'best1821_1900contrast',\n",
    "       'best1900_1950contrast', 'best1950_1990contrast', 'reviewed1850_1950',\n",
    "       'reviewed1850_1950contrast', 'heath', 'heathcontrast', 'mostdiscussed',\n",
    "       'mostdiscussedcontrast', 'usnorton', 'usnortoncontrast', 'nonusnorton',\n",
    "       'nonusnortoncontrast', 'preregistered', 'preregisteredcontrast',\n",
    "       'reviewed1965_1990', 'reviewed1965_1990contrast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best1821_1900\n",
      "All vols:  139\n",
      "US vols:  38\n",
      "Mean date:  1870.5971223\n",
      "\n",
      "best1900_1950\n",
      "All vols:  141\n",
      "US vols:  96\n",
      "Mean date:  1922.4964539\n",
      "\n",
      "best1950_1990\n",
      "All vols:  141\n",
      "US vols:  119\n",
      "Mean date:  1968.4964539\n",
      "\n",
      "anybest\n",
      "All vols:  814\n",
      "US vols:  544\n",
      "Mean date:  1924.97420147\n",
      "\n",
      "best1821_1900contrast\n",
      "All vols:  139\n",
      "US vols:  38\n",
      "Mean date:  1868.61151079\n",
      "\n",
      "best1900_1950contrast\n",
      "All vols:  141\n",
      "US vols:  120\n",
      "Mean date:  1968.73049645\n",
      "\n",
      "best1950_1990contrast\n",
      "All vols:  141\n",
      "US vols:  97\n",
      "Mean date:  1922.23404255\n",
      "\n",
      "reviewed1850_1950\n",
      "All vols:  541\n",
      "US vols:  210\n",
      "Mean date:  1898.17560074\n",
      "\n",
      "reviewed1850_1950contrast\n",
      "All vols:  603\n",
      "US vols:  303\n",
      "Mean date:  1894.48922056\n",
      "\n",
      "heath\n",
      "All vols:  46\n",
      "US vols:  40\n",
      "Mean date:  1902.34782609\n",
      "\n",
      "heathcontrast\n",
      "All vols:  46\n",
      "US vols:  40\n",
      "Mean date:  1903.45652174\n",
      "\n",
      "mostdiscussed\n",
      "All vols:  29\n",
      "US vols:  28\n",
      "Mean date:  1903.13793103\n",
      "\n",
      "mostdiscussedcontrast\n",
      "All vols:  29\n",
      "US vols:  27\n",
      "Mean date:  1903.72413793\n",
      "\n",
      "usnorton\n",
      "All vols:  59\n",
      "US vols:  51\n",
      "Mean date:  1911.08474576\n",
      "\n",
      "usnortoncontrast\n",
      "All vols:  57\n",
      "US vols:  49\n",
      "Mean date:  1910.84210526\n",
      "\n",
      "nonusnorton\n",
      "All vols:  55\n",
      "US vols:  1\n",
      "Mean date:  1890.81818182\n",
      "\n",
      "nonusnortoncontrast\n",
      "All vols:  55\n",
      "US vols:  4\n",
      "Mean date:  1891.2\n",
      "\n",
      "preregistered\n",
      "All vols:  20\n",
      "US vols:  13\n",
      "Mean date:  1905.05\n",
      "\n",
      "preregisteredcontrast\n",
      "All vols:  20\n",
      "US vols:  13\n",
      "Mean date:  1904.85\n",
      "\n",
      "reviewed1965_1990\n",
      "All vols:  97\n",
      "US vols:  96\n",
      "Mean date:  1977.34020619\n",
      "\n",
      "reviewed1965_1990contrast\n",
      "All vols:  95\n",
      "US vols:  91\n",
      "Mean date:  1975.48421053\n"
     ]
    }
   ],
   "source": [
    "for col in cols2check:\n",
    "    print()\n",
    "    print(col)\n",
    "    df = third.loc[third[col] == 1, : ]\n",
    "    print('All vols: ', len(df.isusa))\n",
    "    print('US vols: ', sum(df.isusa))\n",
    "    print('Mean date: ', np.mean(df.latestcomp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
